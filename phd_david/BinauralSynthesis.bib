@Article{MinimumPhaseHilbert,
	title={{Design of Optimal Minimum Phase Digital FIR Filters Using Discrete Hilbert Transforms}},
	author={{Niranjan Damera-Venkata and Shawn R. McCaslin and Brian L. Evans}},
	journal={{IEEE Transactions on Signal Processing}},
	volume="48",
	number = "5",
	pages = {1491-1495},
	month = "May",
	year = "2000",
	url = {{}},
	abstract = {{
		We present a robust non-iterative algorithm to design optimal minimum phase digital FIR filters
		with real or complex coefficients. 
		We derive (1) the discrete Hilbert transform (DHT) 
		of the complex cepstrum of a causal complex minimum phase sequence, and 
		(2) the minimum fast Fourier transform length for computing
		the DHT to achieve a desired coefficient accuracy.
	}}
}

@inproceedings{MinnaarHeadMovement,
	title = {{The importance of head movements for binaural room synthesis}},
	author = {Pauli Minnaar and Søren Krarup Olesen and Flemming Christensen and Henrik Møller},
	booktitle = {{Proceedings of the 2001 International Conference on Auditory Display}},
	month = "July",
	year =  "2001",
	city = "Espoo",
	country = "Findland",
	abstract = {{
     The contribution of head movements to sound
localisation of loudspeakers in a listening room was
investigated. An experiment was done where listeners
either were requested to keep their heads still while sound
was being presented or were allowed to move freely while
seated on a chair. The results give an indication of how
well listeners can perform the task and what contribution
head movements has.
     The same localisation task was performed while
listeners were presented with a simulation of the
loudspeakers implemented by means of binaural
synthesis. As in the “real life” case listeners either had to
sit still or were allowed to move their heads. The binaural
synthesis was implemented by means of measured
binaural room impulse responses (BRIRs), for which the
direct sound was updated according to the head position
of the listener.
     Pilot experiments showed that localisation generally
improves when head movements are allowed, compared
to when listeners keep their heads still during sound
presentations. This encouraging result lead to the design
of a full-scale experiment that is currently under way. The
results will be reported at the ICAD2000 conference.
	}}
}


@article{Menzies06-nearfieldBinauralSynthesis,
	title={{Nearﬁeld binaural synthesis and ambisonics}},
	author={{Dylan Menzies and Marwan Al-Akaidi}},
	journal={{Journal Acoustical Society of America}},
	number=121,
	volume=3,
	pages={1559–1563},
	month="March",
	year=2007,
	doi={10.1121/1.2434761},
	url={{http://www.zenprobe.com/dylan/pubs/menzies06_nearfieldBinauralSynthesis.pdf}},
	abstract={{
		Ambisonic encodings can be rendered binaurally,
		as well as for speaker arrays.
		We ﬁrst consider how binaural signals can be calculated
		from high-order Ambisonic encodings of general soundﬁelds containing near and far sources.
		For sufficently near sources we identify an error resulting
		from the limited ﬁeld of validity of the freeﬁeld harmonic expansion.
		A modiﬁed expansion is derived that can render such sources without error.
	}},
	file={{PROJECT-III/Nearfield_Binaural_syntheiss_and_ambisonics.pdf}}
}

@book{Blauert,
	author={J. Blauert},
	title={Spatial hearing, the psychophysics of human sound localization},
	publisher={MIT Press},
	year=1997,
	comment={{the green book}}
}

@article{LordRayleigh1907,
	author={Lord Rayleigh},
	title={{On our perception of sound direction}},
	journal={{Phil. Mag.}},
	volume={13},
	pages={214-232},
	year=1907,
	comments={First mention to interaural differences of level and time to locate sources.}
}

@techreport{MitHrtf_techreport,
	author={B. Gardner and K. Martin},
	title={{HRTF Meassurements of a KEMAR Dummy-head microphone}},
	number={280},
	institution={MIT Media Lab Perceptual Computing},
	year=1994,
	country={USA},
	state={MA},
	comments={The tech report that explains how to use the MIT KEMAR HRTF's}
}
@article{MitHrtf,
	author={B. Gardner and K. Martin},
	title={{HRTF Meassurements of a KEMAR}},
	journal={J. Acoust. Soc. Am.},
	volume={97},
	number={6},
	pages={3907-3908},
	year={1995},
	abstract = {{
	}},
	comments={The tech report that explains how to use the MIT KEMAR HRTF's}
}

@misc{IrcamHrtf,
	title={{Listen HRTF Database}},
	url={{http://recherche.ircam.fr/equipes/salles/listen/}},
	comments={{The website where the IRCAM HRTF's are available from}}
}

@inproceedings{KreuzerHrtf,
	author={Wolfgang Kreuzer and Zhensheng Chen},
	title={A Fast Multipole Boundary Element Method for Calculating HRTFs},
	booktitle={AES Convention},
	year=2007,
	city={Viena},
	country={Austria},
	abstract={{Methods for measuring head related transfer functions (HRTFs) for an individual person are rather long and complicated. To avoid this problem a numerical model using the Boundary Element Method (BEM) is introduced. In general, such methods have the drawback that the computations for high frequencies are very time- and resource-consuming. To reduce these costs the BEM-model is combined with a fast multipole method (FMM) and a reciprocal approach.
	}}
}

@inproceedings{hamasaki,
	title={{The 22.2 Multichannel Sound System and Its Application}},
	author={K Hamasaki and K Hiyama and R Okumura},
	booktitle={AES 118th Convention},
	city={Barcelona},
	country={Spain},
	year=2005,
}
@inproceedings{hamasaki2,
	title={{5.1 and 22.2 Multichannel Sound Productions Using an Integrated Surround Sound Panning System}},
	author={ K Hamasaki and S Komiyama and K Hiyama and H Okubo},
	booktitle={ Proceedings NAB BEC},
	year=2005,
}
@inproceedings{hamasaki3,
	title={{Advanced multichannel audio systems with superior impression of presence and reality}},
	author={{K Hamasaki and K Hiyama and T Nshiguchi and K Ono}},
	booktitle={{AES 116th Convention}},
	city={Berlin},
	contry={Germany},
	note={Convention paper},
	year=2004
}

@misc{AmbisonicsDotNet,
	title={{Ambisonics.net}},
	url={http://www.ambisonics.net}
	}
	
@misc{SoundfieldDotCom,
	author={{Soundfield Research}},
	title={{Soundfield, an Introduction}},
	url={{http://www.soundfield.com/feature.htm}}
	}

@patent{Gerzon_Soundfield_Patent,
	author = {{M. A. Gerzon and Graham Craven}},
	title = {{Coincident microphone simulation covering three dimensional space and yielding various directional outputs}},
	number = 4042779,
	year  = 1977,
	nationality = {US},
	comment = {{Soundfield microphone patent}}
}
@conference{Gerzon_Soundfield,
	author={M. A. Gerzon},
	title={The Design of Precisely Coincident Microphone Arrays for Stereo and Surround Sound},
	booktitle={Audio Engineering Society Convention 50},
	month={3},
	year={1975},
	url={http://www.aes.org/e-lib/browse.cfm?elib=2466},
	abstract = {{{
So called "coincident" microphone arrays are often used for recording stereo or surround sound. Experience has shown that two of the main causes of poor image localization and of spurious secondary images are: 1) the usual capsule spacing of 3 to 10 cm, and 2) poor polar diagrams and polar phase responses in the treble. These defects also cause a significant degradation in the tonal quality if a stereo or surround sound recording is mixed down to mono or matrixed either to modify the recording's stereo effect or for 2-channel quadraphonic encoding.
	}}}
}

@inproceedings{Satarzadeh_Anthropometry,
	author={{Patrick Satarzadeh1 and V. Ralph Algazi1 and Richard O. Duda1}},
	title={{Physical and Filter Pinna Models Based on Anthropometry}},
	booktitle={AES Convention},
	year=2007,
	city={Viena},
	country={Austria},
	comment={{Tries to relate pinna antropometry to notches in filter models}}
}	

@phdthesis{Wiggins_Phd,
	title={{An investigation into the real-time manipulation and control of three-dimmensional sound fields}},
	author={Bruce Wiggins},
	school={Univertity of Derby},
	year=2004,
	comments={{
		Optimizing decoding.
		Binaural decoding using a single convolution for each Ambisonics channel.
	}}
}

@inproceedings{mooreTabuSearch,
	title={{The Design of Ambisonic Decoders for the ITU 5.1 Layout with Even Performance Characteristics}},
	author={{David Moore and Jonathan Wakefield}},
	booktitle={{124th AES convention}},
	number=7473,
	year=2008,
	city={Amsterdam},
	country={Netherlands}
}

@inproceedings{Daniel_WFSvsAmbisonics,
	title={{Further Investigations of High Order Ambisonics and Wavefield Synthesis for Holophonic Sound Imaging}},
	author={{Jérôme Daniel and Rozenn Nicol and Sébastien Moreau}},
	booktitle={{114th AES convention}},
	year=2003,
	city={Amsterdam},
	country={Netherlands},
	comments={{
		Resumen (en ingles) de la tesis de Daniel
		Resumen de teoria de WFS
			Huygens principle: fuentes secundarias
				En el frente de onda todos los secundarios misma fase
			Formalizacion matematica: Kirchhoff-Heimholtz integral
				No solo presion (dipole) sino su gradiente (monopole) (seguro monopole-dipole?)
				No necesita estar en el frente de onda como Huygens, gradiente incluye info de fase
			Problemas aplicacion practica ideal
				Discrete transducers -> spatial aliasing -> fmax
				Linear not surfaces focusing in horizontal scene
				Coincident monopole and dipoles
				Quality of transducers
			WFS approximation
				Stationary phase approximation -> choose linear horizontal slice, most significative
				Single directivity transducer array -> Just one tranducer (monopole mics, cardioid or 8-fig speakers)
					Real transducers are cardioids on midfreqs, more directive on HF and less in LF
				Notional source encoding: Simulate WFS recording from direct close recordings, using virtual directivity mics
					Also allows decoupling mics and speaker arrays (extrapolation matrix)
			Enclosed sources
				Inverting phase (and delay?). (Verheijen)
				Time reversal (Yon,Tinter)
				...
		Resumen de teoria de ambisonics
			Fundamentos
				Formulas originales de los harmonicos esfericos, proyeccion, ortonormalidad, normalizacion...
				Porque se excluyen las fuentes internas
				Deduce las cilindricas (2D) como un caso especial de las esfericas (3D)
				Encoding de una onda plana
			Decoding
				Enuncia el principio de reencoding como una multiplicacion de matrices (basic)
				Suficientes altavoces? Minimo el mismo que canales
				Decodings fuera del sweetspot (
				Panning function: Ganancias de un altavoz segun el angulo con la onda plana
			Near Field
				Propone un nuevo encoding para el near field que reaprovecha el mismo decoding
				No acabo de entender las diferencias pero parece que el encoding tradicional da filtros inestables
				TODO: En que se diferencian las dos aproximaciones
		Comparacion
			Los modelos ideales son totalmente intercambiables
			Las diferencias estan justo en las aproximaciones que hacen cada uno
			Analisis de diferentes tipos de artefactos introducidos por las aproximaciones
	}}
}

@article{Gerzon_Periphony,
	author={{M. A. Gerzon}},
	title={{Periphony: With-Height Sound Reproduction.}},
	journal={{Journal of the Audio Engineering Society}},
	year=1973,
	number=21,
	volume=1,
	pages={2–10},
	comment={{
		Probablement primer paper del Gerzon sobre ambisonics.
	}}
}

@article{Gerzon_Broadcasting,
	author={{M. A. Gerzon}},
	title={{Ambisonics in Multichannel Broadcasting and Video}}, 
	journal={{Journal of the Audio Engineering Society}},
	city={Vienna},
	volume={33},
	pages={859-871},
	month={November},
	year=1985,
	comment={{paper version of Gerzon_Broadcasting_proceedings}}
}
@inproceedings{Gerzon_Broadcasting_proceedings,
	author={{M. A. Gerzon}},
	title={{Ambisonics in Multichannel Broadcasting and Video}}, 
	booktitle={Proceedings of the 92nd International AES Convention},
	city={Vienna},
	pages={24 – 27},
	month={March},
	year=1992,
	comment={{conference version of Gerzon_Broadcasting}}
}
@article{Gerzon_VienaDecoder,
	author={{M. A. Gerzon and G.J. Barton}},
	title={{ Ambisonic Decoders for HDTV. }}, 
	journal={J. Audio Eng. Soc.},
	volume={33(11)},
	pages={859-871},
	year=1985,
	month={November},
	comment={{
		In this paper Gerzon presents the so called 'viena decodders' for Ambisonics
		How to decode into ITU configurations
	}}
}

@patent{Gerzon_Patent,
	author = {{M. A. Gerzon and G. J. Barton}},
	title = {{Sound Reproduction Systems}},
	number = 1494751,
	year  = 1974,
	nationality = {US},
	comment = {{Ambisonics related patent}}
}


@misc{trinnovTetramic,
	title={{5.0 Sound recording in High Spatial Resolution}},
	author={{Trinnov Audio}},
	date={{10 March 2008}},
	url={{http://www.trinnov.com/download_file.php?file=Trinnov_SRP_GB.pdf}},
}

@article{NeuralBinauralSourceLocalization,
	title={A novel biologically inspired neural network solution for robotic 3D sound source sensing},
	author={Fakheredine Keyrouz and Klaus Diepold},
	journal={{Soft Comput}},
	year={2008},
	volume=12,
	pages={721–729},
	doi={10.1007/s00500-007-0249-9},
	comment={}
}

@book{Blumlein,
	author={{Alexander, Robert Charles}},
	title={{The Inventor of Stereo: The Life and Works of Alan Dower Blumlein}},
	year=1999,
	publisher={{Focal Press}},
	isbn={0-240-51628-1},
	comment={{biografia del inventor del stereo}}
}

@book{ComputationalFluidDynamics,
	author={T. J. Chung},
	title={{Computational Fluid Dynamics}},
	publisher={Cambridge University Press},
	year=2002
}

@article{FDTD,
	author={D. Botteldoren},
	title={Finite-difference time-domain simulation of low-frequency room acoustic problems},
	journal={Acoustical Society of America},
	volume={98(6)},
	year=1995
}

@article{seybertBEM,
	Author = {A. F. Seybert and C. Y. R. Cheng and T. W. Wu},
	Date-Added = {2007-07-26 03:28:28 +0200},
	Date-Modified = {2007-07-26 03:30:24 +0200},
	Journal = {Journal of the Acoustic Society of America},
	Keywords = {bem},
	Month = {September},
	Number = {3},
	Pages = {1612-1618},
	Title = {The solution of coupled interior/exterior acoustic problems using the boundary element method},
	Volume = {88},
	Year = {1990}
}
@mastersthesis{nironenImageSource,
	Author = {Heli Nironen},
	Date-Added = {2007-07-25 18:03:16 +0200},
	Date-Modified = {2007-07-25 18:05:06 +0200},
	school = {Helsinki University of Technology},
	Title = {Diffuse reflections in room acoustics modelling},
	Year = {2004}
}

@article{farinaRayTracing,
    Abstract = {The aim of this paper is to introduce a new computational model (RAMSETE)
for the simulation of sound propagation in large rooms; the model can easily be
adapted to work outdoor, and can consider diffraction effects around screen
edges and sound paths passing through (light) panels.
However, this paper focuses on room acoustics, and particularly on rooms
with non-Sabinian behaviour. In fact, the Pyramid Tracing algorithm does not
involve an hybrid computation scheme, with a reverberant tail superposed to
the deterministic early reflections estimate, as it is common with other
diverging beam tracers (cone tracers, gaussian beam tracers, etc.). This make it
possible to study also sound fields characterised by double-slope sound decays,
inside spaces with not comparable dimensions and inhomogeneous sound
absorption.
It is well known that the same capabilities were already present in the
(original) Ray Tracing scheme, but requiring much longer computation time. In
fact, a correct Ray Tracing implementation can be considered as the reference
standard for any (faster) numerical code based on the Geometrical Acoustics
assumptions.
After a brief introduction to some important details of the two algorithms,
the results obtained in three cases are presented. The first is a typical Sabinian
room (a reverberating chamber), the second is the coupling of two rooms with
different average absorption (a theatre with its stage), the third is a typical
industrial building (having an height very little compared to other dimensions)
with non-uniform sound absorption (baffles under the ceiling).
The results show how the Pyramid Tracing can give results very similar to
the original Ray Tracing, provided that a proper adjustment of the parameters is
performed. On the other hand, the magnitude of the errors that can be done
with improper parameter settings is delimited and discussed.
},
    Author = {A. Farina},
    Date-Added = {2007-06-13 12:40:30 +0200},
    Date-Modified = {2007-06-13 12:45:00 +0200},
    Journal = {Proceedings of International Conference on Computer Acoustics and its Environmental Applications},
    Keywords = {Pyramid Tracing, Geometrical Methods, sound rendering},
    Title = {Pyramid Tracing vs. Ray Tracing for the simulation of sound propagation in large rooms},
    Year = {1995}}

@article{funkhouserBeamTracing,
    Author = {T. Funkhouser and N. Tsingos and I. Carlbom and G. Elko and M. Sondhi and J. West},
    Date-Added = {2007-06-16 21:21:02 +0200},
    Date-Modified = {2007-06-16 21:23:53 +0200},
    Journal = {(invited paper) Forum Acusticum},
    Month = {September},
    Title = {Modeling Sound Reflection and Diffraction in Architectural Environments with Beam Tracing},
    Year = {2002}}


@article{ZotkinAntropometricHrtf, 
	title={HRTF personalization using anthropometric measurements}, 
	author={Zotkin, D.Y.N. and Hwang, J. and Duraiswaini, R. and Davis, L.S.}, 
	journal={Applications of Signal Processing to Audio and Acoustics, 2003 IEEE Workshop on.}, 
	year={2003}, 
	month={October}, 
	volume={}, 
	number={}, 
	pages={157-160}, 
	keywords={ acoustic wave scattering, audio signal processing, physiological models, transfer functions HRTF personalization, anthropometric ear parameters, anthropometric measurements, head-and-torso model, individualized head related transfer functions, localization, sound scattering, spatial audio, subjective perception, virtual auditory scene}, 
	abstract={Individualized head related transfer functions (HRTFs) are needed for accurate rendering of spatial audio, which is important in many applications. Since these are relatively tedious to acquire, they may not be acceptable for some applications. A number of studies have sought to perform simple customization of the HRTF. We propose and test a strategy for HRTF personalization, based on matching certain anthropometric ear parameters with the HRTF database, and the incorporation of a low-frequency "head-and-torso" model. We present preliminary tests aimed at evaluation of this customization. Results show that the approach improves both the accuracy of the localization and subjective perception of the virtual auditory scene.},
	url={{http://ieeexplore.ieee.org/iel5/9038/28686/01285855.pdf}},
	comments={Test method about adapting HRTF antropometric fiting. Curious results that the snowball model for low frequencies improve the results.}
}


@inproceedings{CipicHrtfDb,
	author={V. R. Algazi and R. O. Duda and D. M. Thompson and C. Avendano},
	title={{The CIPIC HRTF Database}},
	booktitle={{Proc. 2001 IEEE Workshop on Applications of Signal Processing to Audio and Electroacoustics}},
	pages={99-102},
	place={Mohonk Mountain House},
	city={New Paltz},
	state={NY}, 
	coutry={US},
	month={October},
	days={21-24},
	year=2001,
	url={{http://interface.cipic.ucdavis.edu/CIL_html/CIL_HRTF_database.htm}},
	comments={Describes how the CPIC HRTF database was compiled. It contains a list of interesting antropometric measures.}
}

@inproceedings{Noisternig_binauralAmbisonics,
	author={Markus Noisternig and Alois Sontacchi and Thomas Musil and Robert Höldrich},
	title={{A 3d ambisonic based binaural sound reproduction system}},
	booktitle={{AES 24th International Conference on Multichannel Audio}},
	month={June},
	year=2003,
	comments={{
		Ambisonics to binaural with room simulation and head tracking.
		They don't talk explicitly about convoluting with the SH components of the HRTF but one each time.
	}}
}

@misc{Malham_BformatManipulation,
	author={Dave Malham},
	title={{Spatial Hearing Mechanisms and Sound Reproduction.}},
	year=1998,
	url={{http://www.york.ac.uk/inst/mustech/3d_audio/ambis2.htm}},
	retrieved={{June,2003}}
}
@misc{Fons_DoesWork,
	author={Fons Adriaensen},
	title={{Why ambisonics works}},
	year=2007,
	month={July},
	url={{http://www.ambisonia.com/wiki/index.php/Why_Ambisonics_Works}},
	retrieved={{June,2009}}
}
@inbook{Martin_CannotWork,
	author={Geoff Martin},
	title={{Introduction to Sound Recording}},
	chapter = {{Why Ambisonics cannot work}},
	publisher = {Geoff Martin},
	year=2006,
	month={October},
	url={{http://www.tonmeister.ca/main/textbook/intro_to_sound_recordingch11.html#x42-83400010.5.2}},
	retrieved={{June,2009}}
}

@phdthesis{Daniel_Phd,
	author = {Jérôme Daniel},
	title = {{ Représentation de champs acoustiques,
application à la transmission et à la reproduction
de scènes sonores complexes dans un contexte multimédia}},
	school = {{Université Paris}},
	year = 1991,
	month = {{July}},
	file = {{PROJECT-III/Daniel_phd.pdf}},
	comment = {{{
	}}}
}
@inbook{Daniel_Phd_decodingTable,
	crossref = "Daniel_Phd",
	pages = 158,
	comment = {{{
		A table with decoding gains formulas for maxre, inphase and maxrv 
	}}}
}


@article{Brown_SphereHrtfs,
	author={{C. Phillip Brown and Richard O. Duda}},
	title= {{A Structural Model for Binaural Sound Synthesis}},
	url = {{http://interface.cipic.ucdavis.edu/PAPERS/Brown1997(Efficient3dHRTFModels).pdf}},
	abstract = {{
A structural model is presented for synthesizing
binaural sound from a monaural source. The model produces
well-controlled vertical as well as horizontal effects. The model is
based on a simplified time-domain description of the physics of
wave propagation and diffraction. The components of the model
have a one-to-one correspondence with the physical sources of
sound diffraction, delay, and reflection. The simplicity of the
model permits efficient implementation in DSP hardware, and
thus facilitates real-time operation. Additionally, the parameters
in the model can be adjusted to fit a particular individual’s
characteristics, thereby producing individualized head-related
transfer functions. Experimental tests verify the perceptual ef-
fectiveness of the approach.
	}},
	keywords = {{Binaural, head-related transfer functions, localization, spatial hearing, 3-D sound, virtual auditory space.
	}},
	comment = {{
		They model parametrized HRTF's based on a time domain model similar to the one we use for analytical.
		They simplify the head to a sphere and provide formulas 	
	}}
}

@book{Woodworth_ExperimentalPsycology,
	author={{R. S. Woodworth}},
	title={{Experimental psychology}},
	year=1962,
	city={{New York}},
	publisher={{Holt, Richard and Winston}},
	comment={{
		It is the reference i saw in most papers to refer the Woodworth/Schlosberg formula.
	}}
}

@book{Kuttruff,
	author={{H. Kuttruff}},
	title={{Room acoustics}},
	editor={{Applied Science}},
	year=1973
}

@Book{Abramowitz_Functions,
	author    = "Milton {Abramowitz} and Irene A. {Stegun}",
	title     = "Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables",
	publisher = "Dover",
	year      =  1964,
	address   = "New York",
	edition   = "9th Dover printing, 10th GPO printing"
}

@conference{montoya2004high,
	title={High Spatial Resolution Multichannel Recording},
	author={Montoya, Sebastien and Bruno, Remy and Laborie, Arnaud},
	booktitle={Audio Engineering Society Convention 116},
	month={5},
	year={2004},
	url={http://www.aes.org/e-lib/browse.cfm?elib=12761},
	comment = {{Presentation of the trinnov tetramic}}
}

@conference{benjamin2010why,
	title={Why Ambisonics Does Work},
	author={Benjamin, Eric and Heller, Aaron and Lee, Richard},
	booktitle={Audio Engineering Society Convention 129},
	month={11},
	year={2010},
	url={http://www.aes.org/e-lib/browse.cfm?elib=15664}
}



#######################

@article{solvang2008_SpectralImpairment2DHOA,
	title={Spectral Impairment of Two-Dimensional Higher Order Ambisonics},
	author={Solvang, Audun},
	journal={J. Audio Eng. Soc},
	volume={56},
	number={4},
	pages={267--279},
	year={2008},
	url={http://www.aes.org/e-lib/browse.cfm?elib=14385},
	abstract={{
When reproducing a two-dimensional higher order Ambisonic soundfield with a uniformly distributed loudspeaker array, there is a tradeoff that depends on the radius of the reproduction area, the order, and the wave number. For classical first-order Ambisonics, perfect reconstruction is possible in a tiny sweet spot, and filtering can be used with a larger number of loudspeakers. However, for a larger sweet spot, higher order Ambisonics must be used and the number of loudspeakers must be matched to the order because filter compensation is not possible. The number of loudspeakers is a tradeoff between spectral impairment at high frequencies and reproduction errors at low frequencies.
	}},
	comments={{
		Formulas chulas en el Apendice para manipular Bessel, Exponenciales, Sumatorios y Fouriers.
		Resume la derivacion del decoding Basic 2D en forma matricial para arrays regulares
		Propone decoding dependiente de la frequencia
		Obtiene analiticas para dos medidas del error de localizacion:
			Intensity: autocorrelacion de p(r,k,theta)
			Relative intensity: division entre dos angulos
			Mean Relative intensity: integral sobre todos los angulos respecto al de referencia
	}}
}

@article{cooper1972_discreteMatrixMultichannelStereo,
	title={Discrete-Matrix Multichannel Stereo},
	author={Cooper, Duane H. and Shiga, Takeo},
	journal={J. Audio Eng. Soc},
	volume={20},
	number={5},
	pages={346--360},
	year={1972},
	url={http://www.aes.org/e-lib/browse.cfm?elib=2070},
	abstract={{
Azimuthal harmonic synthesis generates a universe of matrices (UMX) with maximal input-output azimuthal correlations for two (BMP), three (TMX), four (QMX), etc., intermediary channels. The basic mono-stereo-compatible BMX accepts augmentation channels converting to TMX, QMX, etc., In quadrasonics, the psychoacoustically discrete TMX essentially equals the fully discrete QMX. The feasibility of multichannel disc, broadcast, and tape is profoundly enhanced by the sufficiency of using 2-kHz-wide augmentation channels.
	}},
	comments={{
		First reference on Ambisonics principles
		Cylindrical harmonics
	}}
}

@article{gibson1972compatible,
	title={Compatible FM Broadcasting of Panoramic Sound},
	author={Gibson, J. James and Christensen, Roy M. and Limberg, Allen L.R.},
	journal={J. Audio Eng. Soc},
	volume={20},
	number={10},
	pages={816--822},
	year={1972},
	url={http://www.aes.org/e-lib/browse.cfm?elib=2020},
	abstract={{
A system for four-channel transmission over FM radio is proposed in which the most important information required to convey an acoustic picture around the horizon is allocated to the best available channels on the FM baseband. The least significant channel can be dropped to reduce noise, intermodulation, and cost with very little degradation of angular resolution.
	}},
	comments={{
		segon paper sobre el uso de ambisonics para codificar el campo acustico
	}}
}

@article{poletti2000_UnifiedTheoryHorizontalHolographicSoundSystem,
	title={A Unified Theory of Horizontal Holographic Sound Systems},
	author={Poletti, Mark A.},
	journal={J. Audio Eng. Soc},
	volume={48},
	number={12},
	pages={1155--1182},
	year={2000},
	abstract = {{
A theoretical foundation is developed for horizontal holographic surround sound systems based on the two-dimensional Fourier transform. It is shown how the theory leads to the recording and reproduction of sound fields using circular arrays of microphones and loudspeakers. DFT processing of circular microphone arrays produces the spherical harmonics of the sound field, and is a generalization of certain higher order multipole microphones. The performance of the array is shown to be improved by using directional microphone elements. The angular sinc panning functions arise naturally from the reproduction theory, and a mode-matching approach further verifies that they are optimum at low frequencies. General windowing is reviewed for the control of artifacts at high frequencies and the radial error is proposed as a useful parameter for designing windows. Sound intensity theory is examined for visualizing surround sound fields, and a complex instantaneous velocity is introduced, which is easy to 
generate and equivalent to previous definitions for the case of monochromatic sound fields. The reproduction performance of a five-loudspeaker surround system is examined, and its performance over wider reproduction areas is also considered.
	}},
	keywords = {Acoustic wave velocity, Angular sinc panning functions, Audio acoustics, Audio systems, Directional microphone elements, Discrete Fourier transforms, Holographic surround sound systems, Loudspeakers, Microphones, Mode matching, Sound intensity theory, Sound recording, Sound reproduction, Two dimensional Fourier transform},
	url={http://www.aes.org/e-lib/browse.cfm?elib=12033},
	comments={{
		Cylindrical harmonics.
		Complex formulation of spherical harmonic for ambisonics.
		Ambisonics recording.
		Asimtoticamente holografico.
	}}
}

@conference{daniel1998ambisonics,
	title={Ambisonics Encoding of Other Audio Formats for Multiple Listening Conditions},
	author={Daniel, Jérome and Rault, Jean Bernard and Polack, Jean Dominique},
	booktitle={Audio Engineering Society Convention 105},
	month={9},
	year={1998},
	url={http://www.aes.org/e-lib/browse.cfm?elib=8385},
	abstract={{
When browsing in virtual 3-D environments, a complex sound field should be rendered from multiple audio sources. Since it offers good spatial representation and manipulation possibilities, ambisonics is preferred to other surround encoding systems as an intermediate format. In this paper, several ambisonic decoders are reviewed and designed, which may adapt to different listening conditions, including binaural presentation. Both theoretical justifications and subjective validations are presented. Ambisonic ability to encode multichannel material while preserving its spatial qualities is also discussed.
	}},
	comments={{
	}}
}

@article{poletti2005effect,
	title={Effect of Noise and Transducer Variability on the Performance of Circular Microphone Arrays},
	author={Poletti, Mark A.},
	journal={J. Audio Eng. Soc},
	volume={53},
	number={5},
	pages={371--384},
	year={2005},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13417},
	abstract={{
The practical performance of circular microphone arrays is discussed. Such arrays are useful for the analysis of room acoustics, the recording of live sound fields for surroundsound reproduction, and in teleconferencing applications. They also produce low-cost performance relative to three-dimensional arrays when sound sources and loudspeaker reproduction systems are predominantly in the horizontal plane. The noise performance of circular arrays and their sensitivity to transducer variability are considered, and examples are given for the ideal first-order array. In addition, the analysis of arrays using a recently proposed downsampling technique is included.
	}},
	comments={{
	}}
}

# ref 5 missing


@article{stofringsdal2006planeWaveDecomposition,
	title={Conversion of Discretely Sampled Sound Field Data to Auralization Formats},
	author={Støfringsdal, Bård and Svensson, Peter},
	journal={J. Audio Eng. Soc},
	volume={54},
	number={5},
	pages={380--400},
	year={2006},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13682},
	abstract={{
Sound field simulations at low frequencies often use finite-element or other mesh-based methods. For auralization, output data from these methods need to be converted to a format compatible with auralization methods, such as binaural reproduction, wave field synthesis (WFS), higher order Ambisonics (HOA), or vector base amplitude panning (VBAP). The mesh data can be viewed as a spatial sampling of the sound pressure distribution. A method is proposed for converting the mesh data to plane-wave components using a circular array of virtual sources centered around a reference position. Such a plane-wave decomposition (PWD) is straightforward to process further for auralization. Emphasis is put on generalized modal decompositions of sound fields through singular-value decomposition, and on the relation between modal bandwidth and the ratio of mesh width to wavelength. The special case of a decomposition into cylindrical harmonics is studied in detail. Results are presented for two-dimensional examples, and numerical issues are discussed.
	}},
	comments={{
		Analiza la descomposicion del wave field en ondas planas.
		El apendice explica la conversion entre ondas planas y spherical harmonics.
		Parte del problema de como representar simulaciones de diferentes tipos de cara a despues reproducirlos
	}}
}

# ref 7 is Daniel_WFSvsAmbisonics

@conference{bertet20063d,
	title={3D Sound Field Recording with Higher Order Ambisonics - Objective Measurements and Validation of Spherical Microphone},
	author={Bertet, Stéphanie and Daniel, Jérôme and Moreau, Sébastien},
	booktitle={Audio Engineering Society Convention 120},
	month={5},
	year={2006},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13661},
	abstract={{
Higher Order Ambisonics (HOA) is a flexible approach for representing and rendering 3D sound fields. Nevertheless, lack of effective microphone systems limited its use until recently. As a result of authors’ previous work on the theory and design of spherical microphone arrays, a 4th order HOA microphone has been built, measured and used for natural recording. The present paper first discusses theoretical aspects and physical limitations proper to discrete, relatively small arrays (spatial aliasing, low-frequency estimation). Then it focuses on the objective validation of such microphones. HOA directivities reconstructed from simulated and measured 3D responses are compared to the expected spherical harmonics. Criteria like spatial correlation help characterizing the encoding artifacts due to the model limitations and the prototype imperfections. Impacts on localisation criteria are evaluated.
	}},
	comments={{
		bertet2007HOAAcuracyTests lo usa para Encoding theory, minimal loudspeakers, decoding junto a Daniel
	}}
}

@article{poletti2005three,
	title={Three-Dimensional Surround Sound Systems Based on Spherical Harmonics},
	author={Poletti, Mark A.},
	journal={J. Audio Eng. Soc},
	volume={53},
	number={11},
	pages={1004--1025},
	year={2005},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13396},
	abstract={{
The theory of recording and reproduction of three-dimensional sound fields based on spherical harmonics is reviewed and extended. Free-field, sphere, and general recording arrays are reviewed, and the mode-matching and simple source approaches to sound reproduction in anechoic environments are discussed. Both methods avoid the need for both monopole and dipole loudspeakers—as required by the Kirchhoff–Helmholtz integral. An error analysis is presented and simulation examples are given. It is also shown that the theory can be extended to sound reproduction in reverberant environments.
	}},
	comments={{
	}}
}

# ref 10 (WFS) and 12 (UMA format) skiped

@conference{neukom2006decoding,
	title={Decoding Second Order Ambisonics to 5.1 Surround Systems},
	author={Neukom, Martin},
	booktitle={Audio Engineering Society Convention 121},
	month={10},
	year={2006},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13814},
	abstract={{
In order to play back Higher Order Ambisonics (HOA) in concert, symmetric speaker set-ups with a large number of speakers are used. At the moment the only possibilities to provide Ambisonics to home users are the rendering for headphones with HRTF and the conversion to surround 5.1 systems. This paper shows the difficulties and limitations of the conversion of Higher Order Ambisonics to 5.1 surround and presents some viable solutions.
	}},
	comments={{
	}}
}

@conference{benjamin2006localization,
	title={Localization in Horizontal-Only Ambisonic Systems},
	author={Benjamin, Eric and Heller, Aaron and Lee, Richard},
	booktitle={Audio Engineering Society Convention 121},
	month={10},
	year={2006},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13801},
	abstract={{
Ambisonic reproduction systems are unique in their ability to separately reproduce the pressure and velocity components of the recorded audio signals. Gerzon proposed a theory of localization[1,2] in which the human auditory system is presumed to localize using the direction of the velocity vector in the reproduced sound at low frequencies, and the energy vector at high frequencies. An Ambisonic decoder has the energy and velocity vectors coincident. These are the directions of the apparent source when the listener can turn to face it. [2] Separately maximizing the low-frequency and mid/high-frequency operation of the reproduction system can optimize localization where the listener cannot turn to face the apparent source. We test the localization of horizontal-only Ambisonic reproduction systems using various narrow-band test signals to separately evaluate low-frequency and mid-frequency localization.
	}},
	comments={{
		Son los mismos de why does ambisonics work.
	}}
}

# ref 14 es Gerzon_Broadcasting


@article{Ward01reproductionof,
    author = {Darren B. Ward and Thushara D. Abhayapala and Student Member},
    title = {Reproduction of a Plane-Wave Sound Field Using an Array of Loudspeakers},
    journal = {IEEE Trans. Speech Audio Process},
    year = {2001},
    volume = {9},
    pages = {697--707}
}

@article{poletti1996_EncodingFunctions,
	title={The Design of Encoding Functions for Stereophonic and Polyphonic Sound Systems},
	author={Poletti, Mark A.},
	journal={J. Audio Eng. Soc},
	volume={44},
	number={11},
	pages={948--963},
	year={1996},
	url={http://www.aes.org/e-lib/browse.cfm?elib=7879},
	abstract={{
Recordings of live performances are often made using coincident microphones, which encode directional information into two or more channels. The accurate reproduction of the performance is dependent on the encoding functions implemented by the coincident microphones. The design of encoding functions is developed for stereophonic, full surround (ambisonic), and semicircular surround systems. An optimum stereo encoding is developed, a family of encoding functions is derived for the ambisonic system, and a method for deriving the optimum encoding functions for semicircular surround systems is introduced.
	}},
	comments={{
		Demuestra de que el minimo de altavoces para un decoding exacto en el centro es 2 * Orden  (N Chanels en 2D). (tambien en poletti2000_UnifiedTheoryHorizontalHolographicSoundSystem) 
	}}
}

# ref 17 es Blauert
# ref 18 sobre psicoacustica Moore
# ref 19 procesado de señal
# ref 20 matlab

@conference{dickins1999towards,
	title={Towards Optimal Soundfield Representation},
	author={Dickins, Glenn and Kennedy, Rodney},
	booktitle={Audio Engineering Society Convention 106},
	month={5},
	year={1999},
	url={http://www.aes.org/e-lib/browse.cfm?elib=8255},
	abstract={{
Conventionally a sound field is characterised by the instantaneous pressure variations in an extended region of space. This paper considers an efficient and general representation of an arbitrary sound field based on a spherical harmonic expansion or modes. It is shown how the Taylor series expansion and the Ambisonics sound field representation can be subsumed into the spherical harmonic expansion description. This clarifies the nature and degree of these common approximations and suggests a more natural and efficient generalization.
	}},
	comments={{
		Describe representaciones: Taylor Multidimensional, Spherical Harmonics y Analisis Modal y comenta las diferencias (numero de canales convergencia...) y mapeos entre ellos.
	}}
}

@conference{bertet2007HOAAcuracyTests,
	title={Investigation of the Perceived Spatial Resolution of Higher Order Ambisonics Sound Fields: A Subjective Evaluation Involving Virtual and Real 3D Microphones},
	author={Bertet, Stéphanie and Daniel, Jérôme and Gros, Laëtitia and Parizet, Etienne and Warusfel, Olivier},
	booktitle={Audio Engineering Society Conference: 30th International Conference: Intelligent Audio Environments},
	month={3},
	year={2007},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13925},
	abstract={{
Natural sound field can be reproduced through loudspeakers using ambisonic and Higher Order Ambisonic (HOA) microphone recordings. The HOA sound field encoding approach is based on spherical harmonics decomposition. The more components used to encode the sound field, the finer the spatial resolution is. As a result of previous studies, two HOA (2nd and 4th order) microphone prototypes have been developed. To evaluate the perceived spatial resolution and encoding artefacts on the horizontal plane, a localisation test was performed comparing these prototypes, a SoundField microphone and a simulated ideal 4th order encoding system. The HOA reproduction system was composed of twelve loudspeakers equally distributed on a circle. Thirteen target positions were chosen around the listener. An adjustment method using an auditory pointer was used to avoid bias effects of usual reporting methods. The human localisation error occurring for each of the tested systems has been compared. A statistical analysis showed significance differences when using the 4th order system, the 2nd order system and the SoundField microphone.
	}},
	comments={{
		Describe tests subjetivos de resolucion angular para diferentes ordenes, micros y reproducción.
		Horizontal plane (aunque ambisonics 3d)
		3rd no mejora significativamente respecto a 2nd pero 4th si.
		Parece que el micro de 32 capsulas va bien para el de 4th
		Background:
			Encoding: numero de sensores necesarios segun orden y limitaciones fisicas
			Diferentes tipos de decoding muy resumidos en que se basan y que aportan, numero minimo de altavoces
			Resolucion angular
			Formas para el sujeto de reportar y limitaciones: azimuth elevacion, puntero visual, referencias, puntero acustico...
	}}
}

@conference{bertet2007investigation,
	title={Investigation of the Perceived Spatial Resolution of Higher Order Ambisonics Sound Fields: A Subjective Evaluation Involving Virtual and Real 3D Microphones},
	author={Bertet, Stéphanie and Daniel, Jérôme and Gros, Laëtitia and Parizet, Etienne and Warusfel, Olivier},
	booktitle={Audio Engineering Society Conference: 30th International Conference: Intelligent Audio Environments},
	month={3},
	year={2007},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13925},
	abstract={{
Natural sound field can be reproduced through loudspeakers using ambisonic and Higher Order Ambisonic (HOA) microphone recordings. The HOA sound field encoding approach is based on spherical harmonics decomposition. The more components used to encode the sound field, the finer the spatial resolution is. As a result of previous studies, two HOA (2nd and 4th order) microphone prototypes have been developed. To evaluate the perceived spatial resolution and encoding artefacts on the horizontal plane, a localisation test was performed comparing these prototypes, a SoundField microphone and a simulated ideal 4th order encoding system. The HOA reproduction system was composed of twelve loudspeakers equally distributed on a circle. Thirteen target positions were chosen around the listener. An adjustment method using an auditory pointer was used to avoid bias effects of usual reporting methods. The human localisation error occurring for each of the tested systems has been compared. A statistical analysis showed significance differences when using the 4th order system, the 2nd order system and the SoundField microphone.
	}},
	comments={{
		Experimentos subjetivos sobre la precision angular en la reproduccion de diferentes tecnicas holograficas
		Contexto:
			HOA: Encoding, decodings (short summary of whys for basic, maxre, inphase)
			Subjective localization estudies (minimal human error), in angle differential depending on orientation
				Localization blur:
				At front +-1º to +-4º depending on kind of source
				Other directions 5.5º to 10º
			Discussion on reporting methods:
				Estimating elevation: long train, judgement errors
				Head tracker: shorter training, but no feedback, time lag, and better behind
				Visual pointers (problem visual-auditory bias)
				Auditory pointer (Pulkki)
		Several configurations for recording the sound field
		Proposes a new way of reporting based on auditory pointer but avoiding biases
		Results:
			Third system does not enhance Second but Fourth does
			Pointing method, has bad performance on non frontal
	}}
}

@article{evans1998_hrtfSphericalHarmonics,
	title = {{Analyzing head-related transfer function measurements using surface spherical harmonics}},
	journal={Journal of the Acoustical Society of America},
	year={1998},
	month={October},
	volumen={104},
	number={4},
	author={Evans, Michael J.  and Angus, James A. S. and I. Tew, Anthony},
	url={{http://murphylibrary.uwlax.edu/digital/journals/JASA/JASA1998/pdfs/vol_104/iss_4/2400_1.pdf}},
	abstract={{
A continuous, functional representation of a large set of head-related transfer function measurements (HRTFs) is developed. The HRTFs are represented as a weighted sum of surface spherical harmonics (SSHs) up to degree 17. A Gaussian quadrature method is used to pick out a set of experimentally efficient measurement directions. Anechoic impulse responses are measured for these directions between a source loudspeaker and the entrance to the ear canal of a head-and-torso simulator (HATS). Three separate SSH analyses are carried out: The first forms a SSH representation from the time responses, with the variable onset delay caused by interaural differences intact, by applying the analysis to each time sample in turn. The second SSH model is formed in exactly the same way, except using impulse responses in which the variable onset delays have been equalized. The final SSH analysis is carried out in the frequency domain by applying the technique on a frequency bin by frequency bin basis to the magnitude and unwrapped phase responses of the HRTFs. The accuracy and interpolation performance of each of the computed SSH models is investigated, and the usefulness of the SSH technique in analyzing directional hearing and, particularly, in spatializing sounds is discussed. (C) 1998 Acoustical Society of America. S0001-4966(98)01310-1.
	}},
	comments={{
	}}
}
@conference{abhayapala2007_horizontalPlaneHrtfFourierBessel,
	title={Horizontal Plane HRTF Reproduction Using Continuous Fourier-Bessel Functions},
	author={Abhayapala, Thushara D. and Kennedy, Rodney A. and Zhang, Wen},
	booktitle={Audio Engineering Society Conference: 31st International Conference: New Directions in High Resolution Audio},
	month={6},
	year={2007},
	download={{http://users.cecs.anu.edu.au/~thush/publications/p07_107.pdf}},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13969},
	abstract={{
This paper proposes a method to reproduce the Head Related Transfer Function (HRTF) in the horizontal auditory scene. The method is based on a separable representation which consists of a Fourier Bessel series expansion for the spectral components and a conventional Fourier series expansion for the spatial dependence. The proposed representation can be used to predict HRTFs at any azimuth position and at any frequency sampling point from a finite number of measurements. Implementation details are demonstrated in the paper. Measured HRTFs from a KEMAR manikin and analytically simulated HRTFs were used to validate the fidelity and predictive capabilities of the method. The average mean square error for model reconstruction is less than two percent.
	}},
	comments={{
	}}
}

# Zhang:2009:MEH:1582709.1583835,
@inproceedings{Zhang2009_ModalExpansionHrtf,
	author = {Zhang, Wen and Abhayapala, Thushara D. and Kennedy, Rodney A. and Duraiswami, Ramani},
	title = {Modal expansion of HRTFs: Continuous representation in frequency-range-angle},
	booktitle = {Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
	series = {ICASSP '09},
	year = {2009},
	isbn = {978-1-4244-2353-8},
	pages = {285--288},
	numpages = {4},
	url = {http://dx.doi.org/10.1109/ICASSP.2009.4959576},
	doi = {10.1109/ICASSP.2009.4959576},
	acmid = {1583835},
	publisher = {IEEE Computer Society},
	address = {Washington, DC, USA},
	download = {http://www.umiacs.umd.edu/~ramani/pubs/ZAKD_ICASSP_2009.pdf},
	abstract={{{
This paper proposes a continuous HRTF representation in both 3D spatial and frequency domains. The method is based on the acoustic reciprocity principle and a modal expansion of the wave equation solution to represent the HRTF variations with different variables in separate basis functions. The derived spatial basis modes can achieve HRTF near-field and far-field representation in one formulation. The HRTF frequency components are expanded using Fourier Spherical Bessel series for compact representation. The proposed model can be used to reconstruct HRTFs at any arbitrary position in space and at any frequency point from a finite number of measurements. Analytical simulated and measured HRTFs from a KEMAR are used to validate the model.
	}}},
	comments={{{
	}}}
} 


@article{minimumPhase,
	title={Minimum-phase fir filter design using real cepstrum},
	author={Soo-Chang Pei and Huei-Shan Lin},
	month = {Oct},
	year = {2006},
	volume = {53},
	number = {10},
	pages = {1113--1117},
	download={{http://signal.ee.bilkent.edu.tr/defevent/papers/cr1074.pdf}},
	abstract={{
The real cepstrum is used to design an arbitrary length minimum-phase finite-impulse response filter from a mixed-phase prototype. There is no need to start with the odd-length equiripple linear-phase filter first. Neither the phase-unwrapping nor root-finding procedure is needed. Only two fast Fourier transforms and a recursive procedure are required to find the filter's impulse response from its real cepstrum. The resulting filter's magnitude response is exactly the same as the original one even when the filter is of very high order
	}},
	comments={{
		Explains an optimal algorithm to get the Minimum-Phase filter.
		Nice visual examples of the construction process.
	}}
}


@article{LearningBinauralCues,
	url = {http://www.scientificcommons.org/20698455},
	title = {Auditory learning with binaural cues to localisation},
	author = {Ellis, W. and Rowan, D.},
	year = {2006},
	keywords = {RF Otorhinolaryngology, TA Engineering (General). Civil engineering (General)},
	abstract = {The performance of normal–hearing humans on various auditory discrimination tasks improves with multi–hour practice/training; that is ‘learning’ takes place. However, few studies have investigated this learning for binaural cues over earphones. On the basis of an initial experiment, Wright & Fitzgerald (2001) argued that low–frequency ITD discrimination is not influenced by multi–hour training in general whereas high–frequency ILD discrimination is influenced by multi–hour training. They suggested that the implied difference in time–course between cues may be related to known differences in brain stem processing. However, a subsequent experiment by Rowan & Lutman (2005) indicated, in contrast, that multi–hour training did lead to learning with ITD and at both low and highfrequencies, with time–courses that were at least broadly comparable to Wright & Fitzgerald’s (2001) data on ILD. However, potentially important differences in methodologies between the two studies complicate comparisons of 
learning. The primary aim of the present study was to estimate the time-course of learning on ILD using Rowan & Lutman’s (2005) general methodology to enable a more direct comparison of the timecourses between ILD and ITD. Twelve naïve listeners participated in this experiment. ILD thresholds were measured using a forced choice task combined with an adaptive procedure. Thresholds at 128 Hz and 4000 Hz were measured with all listeners during pre and post test sessions, nominally separated by 11 days. Between pre and post tests, six listeners received training consisting of repeated measurements at 4000 Hz only over 6 separate days amounting to 2160 trials; the others served as untrained controls. ILD thresholds at the trained frequency (4000 Hz) were found to reduce between pre and post test in both groups but the trained group learned significantly more than untrained group. The time-course of learning appeared broadly comparable with that found by Rowan & Lutman (2005) with low and high–frequency ITD 
and Wright & Fitzgerald (2001) with ILD at high–frequency. The implications of these results and suggestions for more detailed statistical investigations of time-course of learning will be discussed.},
	publisher = {British Society of Audiology},
	institution = {e-Prints Soton [http://eprints.soton.ac.uk/perl/oai2] (United Kingdom)},
	comment = {{Learning }}
}

@article{LearningNewPinna,
    author = {Van Wanrooij, Marc M. and Van Opstal, A. John},
    title = {{Relearning sound localization with a new ear.}},
    abstract = {{
                Human sound localization results primarily from the processing of binaural differences in sound level and arrival time for locations in the horizontal plane (azimuth) and of spectral shape cues generated by the head and pinnae for positions in the vertical plane (elevation). The latter mechanism incorporates two processing stages: a spectral-to-spatial mapping stage and a binaural weighting stage that determines the contribution of each ear to perceived elevation as function of sound azimuth. We demonstrated recently that binaural pinna molds virtually abolish the ability to localize sound-source elevation, but, after several weeks, subjects regained normal localization performance. It is not clear which processing stage underlies this remarkable plasticity, because the auditory system could have learned the new spectral cues separately for each ear (spatial-mapping adaptation) or for one ear only, while extending its contribution into the contralateral hemifield (binaural-weighting 
adaptation). To dissociate these possibilities, we applied a long-term monaural spectral perturbation in 13 subjects. Our results show that, in eight experiments, listeners learned to localize accurately with new spectral cues that differed substantially from those provided by their own ears. Interestingly, five subjects, whose spectral cues were not sufficiently perturbed, never yielded stable localization performance. Our findings indicate that the analysis of spectral cues may involve a correlation process between the sensory input and a stored spectral representation of the subject's ears and that learning acts predominantly at a spectral-to-spatial mapping level rather than at the level of binaural weighting.
            }},
    citeulike-article-id = {1610696},
    citeulike-linkout-0 = {http://dx.doi.org/10.1523/JNEUROSCI.0850-05.2005},
    citeulike-linkout-1 = {http://www.jneurosci.org/cgi/content/abstract/25/22/5413},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/15930391},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=15930391},
    day = {1},
    doi = {10.1523/JNEUROSCI.0850-05.2005},
    issn = {1529-2401},
    journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
    keywords = {ear, external, hearing, localization, pinna},
    month = jun,
    number = {22},
    pages = {5413--5424},
    pmid = {15930391},
    posted-at = {2012-06-07 15:16:27},
    priority = {2},
    url = {http://dx.doi.org/10.1523/JNEUROSCI.0850-05.2005},
    volume = {25},
    year = {2005},
	download = {{}},
}

@article{minimumAudibleAngle,
	title={On the Minimum Audible Angle},
	author={Wills, A. W.},
	journal={{Journal Acoustical Society of America}},
	number=30,
	volume=4,
	pages={237-246},
	year=1958,
	doi={10.1121/1.1909553},
	url={{http://asadl.org/jasa/resource/1/jasman/v30/i4/p237_s1}},
	abstract={{
		The difference limen for the azimuth of a source of pure tones was measured as a function of the frequency of the tone and the direction of the source. Tone pulses between 250 and 10 000 cps were sounded in the horizontal plane around the head of a subject seated in an anechoic chamber. The smallest angular separation that can be detected between the sources of two successive tone pulses (the minimum audible angle) was determined for each of three subjects. These threshold angles are analyzed in terms of the corresponding threshold changes in the phase, time, and intensity of the tone at the ears of the subject. A comparison of these thresholds with those reported for dichotic stimulation indicates that the resolution of the direction of a source is determined, at frequencies below about 1400 cps, by interaural differences in phase or time, and at higher frequencies by differences in intensity. When the conditions are optimal for temporal discrimination, the threshold for an interaural difference in time is about 10μsec, and when the conditions are optimal for intensity discrimination, the threshold for an interaural difference in intensity is about 0.5 db.
	}},
	comment={{
		Original definition of the minimum Audible Angle method.
		Later uses and a refinement is Morris-Rakerd
		http://www.pa.msu.edu/acoustics/maa.pdf
	}}
}
