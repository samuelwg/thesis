@Article{MinimumPhaseHilbert,
	title={{Design of Optimal Minimum Phase Digital FIR Filters Using Discrete Hilbert Transforms}},
	author={{Niranjan Damera-Venkata and Shawn R. McCaslin and Brian L. Evans}},
	journal={{IEEE Transactions on Signal Processing}},
	volume="48",
	number = "5",
	pages = {1491-1495},
	month = "May",
	year = "2000",
	url = {{}},
	abstract = {{
		We present a robust non-iterative algorithm to design optimal minimum phase digital FIR filters
		with real or complex coefficients. 
		We derive (1) the discrete Hilbert transform (DHT) 
		of the complex cepstrum of a causal complex minimum phase sequence, and 
		(2) the minimum fast Fourier transform length for computing
		the DHT to achieve a desired coefficient accuracy.
	}}
}

@inproceedings{MinnaarHeadMovement,
	title = {{The importance of head movements for binaural room synthesis}},
	author = {Pauli Minnaar and Søren Krarup Olesen and Flemming Christensen and Henrik Møller},
	booktitle = {{Proceedings of the 2001 International Conference on Auditory Display}},
	month = "July",
	year =  "2001",
	city = "Espoo",
	country = "Findland",
	abstract = {{
     The contribution of head movements to sound
localisation of loudspeakers in a listening room was
investigated. An experiment was done where listeners
either were requested to keep their heads still while sound
was being presented or were allowed to move freely while
seated on a chair. The results give an indication of how
well listeners can perform the task and what contribution
head movements has.
     The same localisation task was performed while
listeners were presented with a simulation of the
loudspeakers implemented by means of binaural
synthesis. As in the “real life” case listeners either had to
sit still or were allowed to move their heads. The binaural
synthesis was implemented by means of measured
binaural room impulse responses (BRIRs), for which the
direct sound was updated according to the head position
of the listener.
     Pilot experiments showed that localisation generally
improves when head movements are allowed, compared
to when listeners keep their heads still during sound
presentations. This encouraging result lead to the design
of a full-scale experiment that is currently under way. The
results will be reported at the ICAD2000 conference.
	}}
}



@article{Menzies06-nearfieldBinauralSynthesis,
	keywords = {{ambisonics, hoa, binaural, nearfield, farfield}},
	title={{Nearﬁeld binaural synthesis and ambisonics}},
	author={{Dylan Menzies and Marwan Al-Akaidi}},
	journal={{Journal Acoustical Society of America}},
	number=121,
	volume=3,
	pages={1559–1563},
	month="March",
	year=2007,
	doi={10.1121/1.2434761},
	url={{http://www.zenprobe.com/dylan/pubs/menzies06_nearfieldBinauralSynthesis.pdf}},
	abstract={{
		Ambisonic encodings can be rendered binaurally,
		as well as for speaker arrays.
		We ﬁrst consider how binaural signals can be calculated
		from high-order Ambisonic encodings of general soundﬁelds containing near and far sources.
		For sufficently near sources we identify an error resulting
		from the limited ﬁeld of validity of the freeﬁeld harmonic expansion.
		A modiﬁed expansion is derived that can render such sources without error.
	}},
	file={{PROJECT-III/Nearfield_Binaural_syntheiss_and_ambisonics.pdf}}
}

@book{Blauert,
	author={J. Blauert},
	title={Spatial hearing, the psychophysics of human sound localization},
	publisher={MIT Press},
	year=1997,
	comment={{the green book}}
}

@article{LordRayleigh1907,
	author={{Lord Rayleigh}},
	title={{On our perception of sound direction}},
	journal={{Phil. Mag.}},
	volume={13},
	pages={214-232},
	year=1907,
	comments={First mention to interaural differences of level and time to locate sources.}
}

@techreport{MitHrtf_techreport,
	author={B. Gardner and K. Martin},
	title={{HRTF Meassurements of a KEMAR Dummy-head microphone}},
	number={280},
	institution={MIT Media Lab Perceptual Computing},
	year=1994,
	country={USA},
	state={MA},
	comments={The tech report that explains how to use the MIT KEMAR HRTF's}
}
@article{MitHrtf,
	author={B. Gardner and K. Martin},
	title={{HRTF Meassurements of a KEMAR}},
	journal={J. Acoust. Soc. Am.},
	volume={97},
	number={6},
	pages={3907-3908},
	year={1995},
	abstract = {{
	}},
	comments={The journal article for MIT KEMAR HRTF}
}

@misc{IrcamHrtf,
	title={{Listen HRTF Database}},
	url={{http://recherche.ircam.fr/equipes/salles/listen/}},
	comments={{The website where the IRCAM HRTF's are available from}}
}

@inproceedings{KreuzerHrtf,
	author={Wolfgang Kreuzer and Zhensheng Chen},
	title={A Fast Multipole Boundary Element Method for Calculating HRTFs},
	booktitle={AES Convention},
	year=2007,
	city={Viena},
	country={Austria},
	abstract={{Methods for measuring head related transfer functions (HRTFs) for an individual person are rather long and complicated. To avoid this problem a numerical model using the Boundary Element Method (BEM) is introduced. In general, such methods have the drawback that the computations for high frequencies are very time- and resource-consuming. To reduce these costs the BEM-model is combined with a fast multipole method (FMM) and a reciprocal approach.
	}}
}

@inproceedings{hamasaki,
	title={{The 22.2 Multichannel Sound System and Its Application}},
	author={K Hamasaki and K Hiyama and R Okumura},
	booktitle={AES 118th Convention},
	city={Barcelona},
	country={Spain},
	year=2005,
}
@inproceedings{hamasaki2,
	title={{5.1 and 22.2 Multichannel Sound Productions Using an Integrated Surround Sound Panning System}},
	author={ K Hamasaki and S Komiyama and K Hiyama and H Okubo},
	booktitle={ Proceedings NAB BEC},
	year=2005,
}
@inproceedings{hamasaki3,
	title={{Advanced multichannel audio systems with superior impression of presence and reality}},
	author={K Hamasaki and K Hiyama and T Nshiguchi and K Ono},
	booktitle={{AES 116th Convention}},
	city={Berlin},
	contry={Germany},
	note={Convention paper},
	year=2004
}

@misc{AmbisonicsDotNet,
	title={{Ambisonics.net}},
	url={http://www.ambisonics.net}
	}
	
@misc{SoundfieldDotCom,
	author={Soundfield Research},
	title={{Soundfield, an Introduction}},
	url={{http://www.soundfield.com/feature.htm}}
	}

@patent{Gerzon_Soundfield_Patent,
	author = {Gerzon, M.A. and Craven, Graham},
	title = {{Coincident microphone simulation covering three dimensional space and yielding various directional outputs}},
	number = 4042779,
	year  = 1977,
	nationality = {US},
	comment = {{Soundfield microphone patent}}
}
@conference{Gerzon_Soundfield,
	author={Gerzon, M.A.},
	title={The Design of Precisely Coincident Microphone Arrays for Stereo and Surround Sound},
	booktitle={Audio Engineering Society Convention 50},
	month={3},
	year={1975},
	url={http://www.aes.org/e-lib/browse.cfm?elib=2466},
	abstract = {{{
So called "coincident" microphone arrays are often used for recording stereo or surround sound. Experience has shown that two of the main causes of poor image localization and of spurious secondary images are: 1) the usual capsule spacing of 3 to 10 cm, and 2) poor polar diagrams and polar phase responses in the treble. These defects also cause a significant degradation in the tonal quality if a stereo or surround sound recording is mixed down to mono or matrixed either to modify the recording's stereo effect or for 2-channel quadraphonic encoding.
	}}}
}

@inproceedings{Satarzadeh_Anthropometry,
	author={{Patrick Satarzadeh and V. Ralph Algazi and Richard O. Duda}},
	title={{Physical and Filter Pinna Models Based on Anthropometry}},
	booktitle={AES Convention},
	year=2007,
	city={Viena},
	country={Austria},
	comment={{Tries to relate pinna antropometry to notches in filter models}}
}	

@phdthesis{Wiggins_Phd,
	title={{An investigation into the real-time manipulation and control of three-dimmensional sound fields}},
	author={Bruce Wiggins},
	school={Univertity of Derby},
	year=2004,
	comments={{
		Optimizing decoding.
		Binaural decoding using a single convolution for each Ambisonics channel.
	}}
}

@inproceedings{mooreTabuSearch,
	title={{The Design of Ambisonic Decoders for the ITU 5.1 Layout with Even Performance Characteristics}},
	author={{David Moore and Jonathan Wakefield}},
	booktitle={{124th AES convention}},
	number=7473,
	year=2008,
	city={Amsterdam},
	country={Netherlands}
}

@inproceedings{Daniel_WFSvsAmbisonics,
	title={{Further Investigations of High Order Ambisonics and Wavefield Synthesis for Holophonic Sound Imaging}},
	author={{Jérôme Daniel and Rozenn Nicol and Sébastien Moreau}},
	booktitle={{114th AES convention}},
	year=2003,
	city={Amsterdam},
	country={Netherlands},
	comments={{
		Resumen (en ingles) de la tesis de Daniel
		Resumen de teoria de WFS
			Huygens principle: fuentes secundarias
				En el frente de onda todos los secundarios misma fase
			Formalizacion matematica: Kirchhoff-Heimholtz integral
				No solo presion (dipole) sino su gradiente (monopole) (seguro monopole-dipole?)
				No necesita estar en el frente de onda como Huygens, gradiente incluye info de fase
			Problemas aplicacion practica ideal
				Discrete transducers -> spatial aliasing -> fmax
				Linear not surfaces focusing in horizontal scene
				Coincident monopole and dipoles
				Quality of transducers
			WFS approximation
				Stationary phase approximation -> choose linear horizontal slice, most significative
				Single directivity transducer array -> Just one tranducer (monopole mics, cardioid or 8-fig speakers)
					Real transducers are cardioids on midfreqs, more directive on HF and less in LF
				Notional source encoding: Simulate WFS recording from direct close recordings, using virtual directivity mics
					Also allows decoupling mics and speaker arrays (extrapolation matrix)
			Enclosed sources
				Inverting phase (and delay?). (Verheijen)
				Time reversal (Yon,Tinter)
				...
		Resumen de teoria de ambisonics
			Fundamentos
				Formulas originales de los harmonicos esfericos, proyeccion, ortonormalidad, normalizacion...
				Porque se excluyen las fuentes internas
				Deduce las cilindricas (2D) como un caso especial de las esfericas (3D)
				Encoding de una onda plana
			Decoding
				Enuncia el principio de reencoding como una multiplicacion de matrices (basic)
				Suficientes altavoces? Minimo el mismo que canales
				Decodings fuera del sweetspot (
				Panning function: Ganancias de un altavoz segun el angulo con la onda plana
			Near Field
				Propone un nuevo encoding para el near field que reaprovecha el mismo decoding
				No acabo de entender las diferencias pero parece que el encoding tradicional da filtros inestables
				TODO: En que se diferencian las dos aproximaciones
		Comparacion
			Los modelos ideales son totalmente intercambiables
			Las diferencias estan justo en las aproximaciones que hacen cada uno
			Analisis de diferentes tipos de artefactos introducidos por las aproximaciones
	}}
}

@article{Gerzon_Periphony,
	author={Gerzon, M.A.},
	title={{Periphony: With-Height Sound Reproduction.}},
	journal={{Journal of the Audio Engineering Society}},
	year=1973,
	number=21,
	volume=1,
	pages={2–10},
	comment={{
		Primer paper del Gerzon sobre ambisonics.
	}}
}

@article{Gerzon_Broadcasting,
	author={{Gerzon, M.A.}},
	title={{Ambisonics in Multichannel Broadcasting and Video}}, 
	journal={{Journal of the Audio Engineering Society}},
	city={Vienna},
	volume={33},
	pages={859-871},
	month={November},
	year=1985,
	comment={{paper version of Gerzon_Broadcasting_proceedings}}
}
@inproceedings{Gerzon_Broadcasting_proceedings,
	author={{Gerzon, M.A.}},
	title={{Ambisonics in Multichannel Broadcasting and Video}}, 
	booktitle={Proceedings of the 92nd International AES Convention},
	city={Vienna},
	pages={24 – 27},
	month={March},
	year=1992,
	comment={{conference version of Gerzon_Broadcasting}}
}

@article{Gerzon_VienaDecoder,
	author={{Gerzon, M.A. and G.J. Barton}},
	title={{ Ambisonic Decoders for HDTV. }}, 
	journal={J. Audio Eng. Soc.},
	volume={33(11)},
	pages={859-871},
	year=1985,
	month={November},
	comment={{
		In this paper Gerzon presents the so called 'viena decodders' for Ambisonics
		How to decode into ITU configurations
	}}
}

@patent{Gerzon_Patent,
	author = {{Gerzon, M.A. and G. J. Barton}},
	title = {{Sound Reproduction Systems}},
	number = 1494751,
	year  = 1974,
	nationality = {US},
	comment = {{Ambisonics related patent}}
}


@misc{trinnovTetramic,
	title={{5.0 Sound recording in High Spatial Resolution}},
	author={{Trinnov Audio}},
	date={{10 March 2008}},
	url={{http://www.trinnov.com/download_file.php?file=Trinnov_SRP_GB.pdf}},
}

@article{NeuralBinauralSourceLocalization,
	title={A novel biologically inspired neural network solution for robotic 3D sound source sensing},
	author={Fakheredine Keyrouz and Klaus Diepold},
	journal={{Soft Comput}},
	year={2008},
	volume=12,
	pages={721–729},
	doi={10.1007/s00500-007-0249-9},
	comment={}
}

@book{Blumlein,
	author={{Alexander, Robert Charles}},
	title={{The Inventor of Stereo: The Life and Works of Alan Dower Blumlein}},
	year=1999,
	publisher={{Focal Press}},
	isbn={0-240-51628-1},
	comment={{biografia del inventor del stereo}}
}

@book{ComputationalFluidDynamics,
	author={T. J. Chung},
	title={{Computational Fluid Dynamics}},
	publisher={Cambridge University Press},
	year=2002
}

@article{FDTD,
	author={D. Botteldoren},
	title={Finite-difference time-domain simulation of low-frequency room acoustic problems},
	journal={Acoustical Society of America},
	volume={98(6)},
	year=1995
}

@article{seybertBEM,
	Author = {A. F. Seybert and C. Y. R. Cheng and T. W. Wu},
	Date-Added = {2007-07-26 03:28:28 +0200},
	Date-Modified = {2007-07-26 03:30:24 +0200},
	Journal = {Journal of the Acoustic Society of America},
	Keywords = {bem},
	Month = {September},
	Number = {3},
	Pages = {1612-1618},
	Title = {The solution of coupled interior/exterior acoustic problems using the boundary element method},
	Volume = {88},
	Year = {1990}
}
@mastersthesis{nironenImageSource,
	Author = {Heli Nironen},
	Date-Added = {2007-07-25 18:03:16 +0200},
	Date-Modified = {2007-07-25 18:05:06 +0200},
	school = {Helsinki University of Technology},
	Title = {Diffuse reflections in room acoustics modelling},
	Year = {2004}
}

@article{farinaRayTracing,
    Abstract = {The aim of this paper is to introduce a new computational model (RAMSETE)
for the simulation of sound propagation in large rooms; the model can easily be
adapted to work outdoor, and can consider diffraction effects around screen
edges and sound paths passing through (light) panels.
However, this paper focuses on room acoustics, and particularly on rooms
with non-Sabinian behaviour. In fact, the Pyramid Tracing algorithm does not
involve an hybrid computation scheme, with a reverberant tail superposed to
the deterministic early reflections estimate, as it is common with other
diverging beam tracers (cone tracers, gaussian beam tracers, etc.). This make it
possible to study also sound fields characterised by double-slope sound decays,
inside spaces with not comparable dimensions and inhomogeneous sound
absorption.
It is well known that the same capabilities were already present in the
(original) Ray Tracing scheme, but requiring much longer computation time. In
fact, a correct Ray Tracing implementation can be considered as the reference
standard for any (faster) numerical code based on the Geometrical Acoustics
assumptions.
After a brief introduction to some important details of the two algorithms,
the results obtained in three cases are presented. The first is a typical Sabinian
room (a reverberating chamber), the second is the coupling of two rooms with
different average absorption (a theatre with its stage), the third is a typical
industrial building (having an height very little compared to other dimensions)
with non-uniform sound absorption (baffles under the ceiling).
The results show how the Pyramid Tracing can give results very similar to
the original Ray Tracing, provided that a proper adjustment of the parameters is
performed. On the other hand, the magnitude of the errors that can be done
with improper parameter settings is delimited and discussed.
},
    Author = {A. Farina},
    Date-Added = {2007-06-13 12:40:30 +0200},
    Date-Modified = {2007-06-13 12:45:00 +0200},
    Journal = {Proceedings of International Conference on Computer Acoustics and its Environmental Applications},
    Keywords = {Pyramid Tracing, Geometrical Methods, sound rendering},
    Title = {Pyramid Tracing vs. Ray Tracing for the simulation of sound propagation in large rooms},
    Year = {1995}}

@article{funkhouserBeamTracing,
    Author = {T. Funkhouser and N. Tsingos and I. Carlbom and G. Elko and M. Sondhi and J. West},
    Date-Added = {2007-06-16 21:21:02 +0200},
    Date-Modified = {2007-06-16 21:23:53 +0200},
    Journal = {(invited paper) Forum Acusticum},
    Month = {September},
    Title = {Modeling Sound Reflection and Diffraction in Architectural Environments with Beam Tracing},
    Year = {2002}}


@article{ZotkinAntropometricHrtf, 
	title={HRTF personalization using anthropometric measurements}, 
	author={Zotkin, D.Y.N. and Hwang, J. and Duraiswaini, R. and Davis, L.S.}, 
	journal={Applications of Signal Processing to Audio and Acoustics, 2003 IEEE Workshop on.}, 
	year={2003}, 
	month={October}, 
	volume={}, 
	number={}, 
	pages={157-160}, 
	keywords={ acoustic wave scattering, audio signal processing, physiological models, transfer functions HRTF personalization, anthropometric ear parameters, anthropometric measurements, head-and-torso model, individualized head related transfer functions, localization, sound scattering, spatial audio, subjective perception, virtual auditory scene}, 
	abstract={Individualized head related transfer functions (HRTFs) are needed for accurate rendering of spatial audio, which is important in many applications. Since these are relatively tedious to acquire, they may not be acceptable for some applications. A number of studies have sought to perform simple customization of the HRTF. We propose and test a strategy for HRTF personalization, based on matching certain anthropometric ear parameters with the HRTF database, and the incorporation of a low-frequency "head-and-torso" model. We present preliminary tests aimed at evaluation of this customization. Results show that the approach improves both the accuracy of the localization and subjective perception of the virtual auditory scene.},
	url={{http://ieeexplore.ieee.org/iel5/9038/28686/01285855.pdf}},
	comments={Test method about adapting HRTF antropometric fiting. Curious results that the snowball model for low frequencies improve the results.}
}


@inproceedings{CipicHrtfDb,
	author={V. R. Algazi and R. O. Duda and D. M. Thompson and C. Avendano},
	title={{The CIPIC HRTF Database}},
	booktitle={{Proc. 2001 IEEE Workshop on Applications of Signal Processing to Audio and Electroacoustics}},
	pages={99-102},
	place={Mohonk Mountain House},
	city={New Paltz},
	state={NY}, 
	coutry={US},
	month={October},
	days={21-24},
	year=2001,
	url={{http://interface.cipic.ucdavis.edu/CIL_html/CIL_HRTF_database.htm}},
	comments={Describes how the CPIC HRTF database was compiled. It contains a list of interesting antropometric measures.}
}

@inproceedings{Noisternig_binauralAmbisonics,
	author={Markus Noisternig and Alois Sontacchi and Thomas Musil and Robert Höldrich},
	title={{A 3d ambisonic based binaural sound reproduction system}},
	booktitle={{AES 24th International Conference on Multichannel Audio}},
	month={June},
	year=2003,
	comments={{
		Ambisonics to binaural with room simulation and head tracking.
		They don't talk explicitly about convoluting with the SH components of the HRTF but one each time.
	}}
}

@misc{Malham_BformatManipulation,
	author={Dave Malham},
	title={{Spatial Hearing Mechanisms and Sound Reproduction.}},
	year=1998,
	url={{http://www.york.ac.uk/inst/mustech/3d_audio/ambis2.htm}},
	retrieved={{June,2003}},
	comments={{
		web page explaining the basics of ambisonics
		coding, mono to binaural, Bformat, stereo decoding
	}},
}

@misc{Fons_DoesWork,
	author={Fons Adriaensen},
	title={{Why ambisonics works}},
	year=2007,
	month={July},
	url={{http://www.ambisonia.com/wiki/index.php/Why_Ambisonics_Works}},
	retrieved={{June,2009}}
}
@inbook{Martin_CannotWork,
	author={Geoff Martin},
	title={{Introduction to Sound Recording}},
	chapter = {{Why Ambisonics cannot work}},
	publisher = {Geoff Martin},
	year=2006,
	month={October},
	url={{http://www.tonmeister.ca/main/textbook/intro_to_sound_recordingch11.html#x42-83400010.5.2}},
	retrieved={{June,2009}}
}

@phdthesis{Daniel_Phd,
	author = {Jérôme Daniel},
	title = {{ Représentation de champs acoustiques,
application à la transmission et à la reproduction
de scènes sonores complexes dans un contexte multimédia}},
	school = {{Université Paris}},
	year = 1991,
	month = {{July}},
	file = {{PROJECT-III/Daniel_phd.pdf}},
	comment = {{{
	}}}
}
@inbook{Daniel_Phd_decodingTable,
	crossref = "Daniel_Phd",
	pages = 158,
	comment = {{{
		A table with decoding gains formulas for maxre, inphase and maxrv 
	}}}
}


@book{Woodworth_ExperimentalPsycology,
	author={{R. S. Woodworth}},
	title={{Experimental psychology}},
	year=1962,
	city={{New York}},
	publisher={{Holt, Richard and Winston}},
	comment={{
		It is the reference i saw in most papers to refer the Woodworth/Schlosberg formula.
	}}
}

@book{Kuttruff,
	author={{H. Kuttruff}},
	title={{Room acoustics}},
	editor={{Applied Science}},
	year=1973
}

@Book{Abramowitz_Functions,
	author    = "Milton {Abramowitz} and Irene A. {Stegun}",
	title     = "Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables",
	publisher = "Dover",
	year      =  1964,
	address   = "New York",
	edition   = "9th Dover printing, 10th GPO printing"
}

@conference{montoya2004high,
	title={High Spatial Resolution Multichannel Recording},
	author={Montoya, Sebastien and Bruno, Remy and Laborie, Arnaud},
	booktitle={Audio Engineering Society Convention 116},
	month={5},
	year={2004},
	url={http://www.aes.org/e-lib/browse.cfm?elib=12761},
	comment = {{Presentation of the trinnov tetramic}}
}

@conference{benjamin2010why,
	title={Why Ambisonics Does Work},
	author={Benjamin, Eric and Heller, Aaron and Lee, Richard},
	booktitle={Audio Engineering Society Convention 129},
	month={11},
	year={2010},
	url={http://www.aes.org/e-lib/browse.cfm?elib=15664}
}



#######################

@article{solvang2008_SpectralImpairment2DHOA,
	title={Spectral Impairment of Two-Dimensional Higher Order Ambisonics},
	author={Solvang, Audun},
	journal={J. Audio Eng. Soc},
	volume={56},
	number={4},
	pages={267--279},
	year={2008},
	url={http://www.aes.org/e-lib/browse.cfm?elib=14385},
	abstract={{
When reproducing a two-dimensional higher order Ambisonic soundfield with a uniformly distributed loudspeaker array, there is a tradeoff that depends on the radius of the reproduction area, the order, and the wave number. For classical first-order Ambisonics, perfect reconstruction is possible in a tiny sweet spot, and filtering can be used with a larger number of loudspeakers. However, for a larger sweet spot, higher order Ambisonics must be used and the number of loudspeakers must be matched to the order because filter compensation is not possible. The number of loudspeakers is a tradeoff between spectral impairment at high frequencies and reproduction errors at low frequencies.
	}},
	comments={{
		Formulas chulas en el Apendice para manipular Bessel, Exponenciales, Sumatorios y Fouriers.
		Resume la derivacion del decoding Basic 2D en forma matricial para arrays regulares
		Propone decoding dependiente de la frequencia
		Obtiene analiticas para dos medidas del error de localizacion:
			Intensity: autocorrelacion de p(r,k,theta)
			Relative intensity: division entre dos angulos
			Mean Relative intensity: integral sobre todos los angulos respecto al de referencia
	}}
}

# The Ambisonics pioneers

@article{cooper1972_discreteMatrixMultichannelStereo,
	title={Discrete-Matrix Multichannel Stereo},
	author={Cooper, Duane H. and Shiga, Takeo},
	journal={J. Audio Eng. Soc},
	volume={20},
	number={5},
	pages={346--360},
	year={1972},
	url={http://www.aes.org/e-lib/browse.cfm?elib=2070},
	abstract={{
Azimuthal harmonic synthesis generates a universe of matrices (UMX) with maximal input-output azimuthal correlations for two (BMP), three (TMX), four (QMX), etc., intermediary channels. The basic mono-stereo-compatible BMX accepts augmentation channels converting to TMX, QMX, etc., In quadrasonics, the psychoacoustically discrete TMX essentially equals the fully discrete QMX. The feasibility of multichannel disc, broadcast, and tape is profoundly enhanced by the sufficiency of using 2-kHz-wide augmentation channels.
	}},
	comments={{
		First reference on Ambisonics principles
		Cylindrical harmonics
		Basic paper on the Hierarchical ideas refined in Ambisonics
		According Gerzon http://www.york.ac.uk/inst/mustech/3d_audio/gerzonrf.htm
	}}
}

@article{gibson1972compatible,
	title={Compatible FM Broadcasting of Panoramic Sound},
	author={Gibson, J. James and Christensen, Roy M. and Limberg, Allen L.R.},
	journal={J. Audio Eng. Soc},
	volume={20},
	number={10},
	pages={816--822},
	year={1972},
	url={http://www.aes.org/e-lib/browse.cfm?elib=2020},
	abstract={{
A system for four-channel transmission over FM radio is proposed in which the most important information required to convey an acoustic picture around the horizon is allocated to the best available channels on the FM baseband. The least significant channel can be dropped to reduce noise, intermodulation, and cost with very little degradation of angular resolution.
	}},
	comments={{
		segon paper sobre el uso de ambisonics para codificar el campo acustico
		http://www.york.ac.uk/inst/mustech/3d_audio/gerzonrf.htm
		Gerzon comment: Although primarily about FM broadcast methods 
		for surround-sound, this paper describes the hierarchical approach 
		both for horizontal and with-height surround sound based on directional
		harmonics and spherical harmonics also used in Ambisonics
	}}
}

@article{Fellgett1972_directionalInformation,
	author = {P.B. Fellgett},
	title = {Directional Information in Reproduced Sound},
	journal = {Wireless World},
	volume = 78,
	pages = {413-417},
	year = 1972,
	month = Sep,
}

@article{Gerzon_Psychoacoustics,
	author = {Gerzon, M.A.},
	title = {Surround Sound Psychoacoustics},
	journal = {Wireless World},
	volume = 80,
	pages = {483-486},
	year = 1974,
	month = Dec,
	abstract = {{
		There are a number of different mechanisms by which the ears localize sounds, including several low-frequency, mid-frequency, and high-frequency mechanisms, as well as information derived from the reverberation of sounds. With only a few transmission channels available, one cannot hope to satisfy them all, but most existing “discrete” and “matrix” systems do not satisfy more than one or two criteria. The approaches associated with the Nippon Columbia UMX system and the NRDC ambisonic system are the only ones so far to adequately allow for several criteria.
	}},
	comment = {{
		Gerzon comment: http://www.york.ac.uk/inst/mustech/3d_audio/gerzonrf.htm
		The first, and clearest, publication of the psychoacoustic decoding theory behind Ambisonic decoding
		Other cues than ILD and ITD where just experimented at that time
			Head movements, pinna effects...
		But justifies the system because addressing the known cues is not enough
		So lets reproduce the whole sound field
		}},
	download = {{http://www.audiosignal.co.uk/Resources/Surround_sound_psychoacoustics_A4.pdf}},
}




@article{poletti2000_UnifiedTheoryHorizontalHolographicSoundSystem,
	title={A Unified Theory of Horizontal Holographic Sound Systems},
	author={Poletti, Mark A.},
	journal={J. Audio Eng. Soc},
	volume={48},
	number={12},
	pages={1155--1182},
	year={2000},
	abstract = {{
A theoretical foundation is developed for horizontal holographic surround sound systems based on the two-dimensional Fourier transform. It is shown how the theory leads to the recording and reproduction of sound fields using circular arrays of microphones and loudspeakers. DFT processing of circular microphone arrays produces the spherical harmonics of the sound field, and is a generalization of certain higher order multipole microphones. The performance of the array is shown to be improved by using directional microphone elements. The angular sinc panning functions arise naturally from the reproduction theory, and a mode-matching approach further verifies that they are optimum at low frequencies. General windowing is reviewed for the control of artifacts at high frequencies and the radial error is proposed as a useful parameter for designing windows. Sound intensity theory is examined for visualizing surround sound fields, and a complex instantaneous velocity is introduced, which is easy to generate and equivalent to previous definitions for the case of monochromatic sound fields. The reproduction performance of a five-loudspeaker surround system is examined, and its performance over wider reproduction areas is also considered.
	}},
	keywords = {Acoustic wave velocity, Angular sinc panning functions, Audio acoustics, Audio systems, Directional microphone elements, Discrete Fourier transforms, Holographic surround sound systems, Loudspeakers, Microphones, Mode matching, Sound intensity theory, Sound recording, Sound reproduction, Two dimensional Fourier transform},
	url={http://www.aes.org/e-lib/browse.cfm?elib=12033},
	comments={{
		Cylindrical harmonics.
		Complex formulation of spherical harmonic for ambisonics.
		Ambisonics recording.
		Asimtoticamente holografico.
	}}
}

@conference{daniel1998ambisonics,
	title={Ambisonics Encoding of Other Audio Formats for Multiple Listening Conditions},
	author={Daniel, Jérome and Rault, Jean Bernard and Polack, Jean Dominique},
	booktitle={Audio Engineering Society Convention 105},
	month={9},
	year={1998},
	url={http://www.aes.org/e-lib/browse.cfm?elib=8385},
	abstract={{
When browsing in virtual 3-D environments, a complex sound field should be rendered from multiple audio sources. Since it offers good spatial representation and manipulation possibilities, ambisonics is preferred to other surround encoding systems as an intermediate format. In this paper, several ambisonic decoders are reviewed and designed, which may adapt to different listening conditions, including binaural presentation. Both theoretical justifications and subjective validations are presented. Ambisonic ability to encode multichannel material while preserving its spatial qualities is also discussed.
	}},
	comments={{
	}}
}

@article{poletti2005effect,
	title={Effect of Noise and Transducer Variability on the Performance of Circular Microphone Arrays},
	author={Poletti, Mark A.},
	journal={J. Audio Eng. Soc},
	volume={53},
	number={5},
	pages={371--384},
	year={2005},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13417},
	abstract={{
The practical performance of circular microphone arrays is discussed. Such arrays are useful for the analysis of room acoustics, the recording of live sound fields for surroundsound reproduction, and in teleconferencing applications. They also produce low-cost performance relative to three-dimensional arrays when sound sources and loudspeaker reproduction systems are predominantly in the horizontal plane. The noise performance of circular arrays and their sensitivity to transducer variability are considered, and examples are given for the ideal first-order array. In addition, the analysis of arrays using a recently proposed downsampling technique is included.
	}},
	comments={{
	}}
}

# ref 5 missing


@article{stofringsdal2006planeWaveDecomposition,
	title={Conversion of Discretely Sampled Sound Field Data to Auralization Formats},
	author={Støfringsdal, Bård and Svensson, Peter},
	journal={J. Audio Eng. Soc},
	volume={54},
	number={5},
	pages={380--400},
	year={2006},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13682},
	abstract={{
Sound field simulations at low frequencies often use finite-element or other mesh-based methods. For auralization, output data from these methods need to be converted to a format compatible with auralization methods, such as binaural reproduction, wave field synthesis (WFS), higher order Ambisonics (HOA), or vector base amplitude panning (VBAP). The mesh data can be viewed as a spatial sampling of the sound pressure distribution. A method is proposed for converting the mesh data to plane-wave components using a circular array of virtual sources centered around a reference position. Such a plane-wave decomposition (PWD) is straightforward to process further for auralization. Emphasis is put on generalized modal decompositions of sound fields through singular-value decomposition, and on the relation between modal bandwidth and the ratio of mesh width to wavelength. The special case of a decomposition into cylindrical harmonics is studied in detail. Results are presented for two-dimensional examples, and numerical issues are discussed.
	}},
	comments={{
		Analiza la descomposicion del wave field en ondas planas.
		El apendice explica la conversion entre ondas planas y spherical harmonics.
		Parte del problema de como representar simulaciones de diferentes tipos de cara a despues reproducirlos
	}}
}

# ref 7 is Daniel_WFSvsAmbisonics

@conference{bertet20063d,
	title={3D Sound Field Recording with Higher Order Ambisonics - Objective Measurements and Validation of Spherical Microphone},
	author={Bertet, Stéphanie and Daniel, Jérôme and Moreau, Sébastien},
	booktitle={Audio Engineering Society Convention 120},
	month={5},
	year={2006},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13661},
	abstract={{
Higher Order Ambisonics (HOA) is a flexible approach for representing and rendering 3D sound fields. Nevertheless, lack of effective microphone systems limited its use until recently. As a result of authors’ previous work on the theory and design of spherical microphone arrays, a 4th order HOA microphone has been built, measured and used for natural recording. The present paper first discusses theoretical aspects and physical limitations proper to discrete, relatively small arrays (spatial aliasing, low-frequency estimation). Then it focuses on the objective validation of such microphones. HOA directivities reconstructed from simulated and measured 3D responses are compared to the expected spherical harmonics. Criteria like spatial correlation help characterizing the encoding artifacts due to the model limitations and the prototype imperfections. Impacts on localisation criteria are evaluated.
	}},
	comments={{
		bertet2007HOAAcuracyTests lo usa para Encoding theory, minimal loudspeakers, decoding junto a Daniel
	}}
}

@article{poletti2005three,
	title={Three-Dimensional Surround Sound Systems Based on Spherical Harmonics},
	author={Poletti, Mark A.},
	journal={J. Audio Eng. Soc},
	volume={53},
	number={11},
	pages={1004--1025},
	year={2005},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13396},
	abstract={{
The theory of recording and reproduction of three-dimensional sound fields based on spherical harmonics is reviewed and extended. Free-field, sphere, and general recording arrays are reviewed, and the mode-matching and simple source approaches to sound reproduction in anechoic environments are discussed. Both methods avoid the need for both monopole and dipole loudspeakers—as required by the Kirchhoff–Helmholtz integral. An error analysis is presented and simulation examples are given. It is also shown that the theory can be extended to sound reproduction in reverberant environments.
	}},
	comments={{
	}}
}

# ref 10 (WFS) and 12 (UMA format) skiped

@conference{neukom2006decoding,
	title={Decoding Second Order Ambisonics to 5.1 Surround Systems},
	author={Neukom, Martin},
	booktitle={Audio Engineering Society Convention 121},
	month={10},
	year={2006},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13814},
	abstract={{
In order to play back Higher Order Ambisonics (HOA) in concert, symmetric speaker set-ups with a large number of speakers are used. At the moment the only possibilities to provide Ambisonics to home users are the rendering for headphones with HRTF and the conversion to surround 5.1 systems. This paper shows the difficulties and limitations of the conversion of Higher Order Ambisonics to 5.1 surround and presents some viable solutions.
	}},
	comments={{
	}}
}

@conference{benjamin2006localization,
	title={Localization in Horizontal-Only Ambisonic Systems},
	author={Benjamin, Eric and Heller, Aaron and Lee, Richard},
	booktitle={Audio Engineering Society Convention 121},
	month={10},
	year={2006},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13801},
	abstract={{
Ambisonic reproduction systems are unique in their ability to separately reproduce the pressure and velocity components of the recorded audio signals. Gerzon proposed a theory of localization[1,2] in which the human auditory system is presumed to localize using the direction of the velocity vector in the reproduced sound at low frequencies, and the energy vector at high frequencies. An Ambisonic decoder has the energy and velocity vectors coincident. These are the directions of the apparent source when the listener can turn to face it. [2] Separately maximizing the low-frequency and mid/high-frequency operation of the reproduction system can optimize localization where the listener cannot turn to face the apparent source. We test the localization of horizontal-only Ambisonic reproduction systems using various narrow-band test signals to separately evaluate low-frequency and mid-frequency localization.
	}},
	comments={{
		Son los mismos de why does ambisonics work.
	}}
}

# ref 14 es Gerzon_Broadcasting


@article{Ward01reproductionof,
    author = {Darren B. Ward and Thushara D. Abhayapala and Student Member},
    title = {Reproduction of a Plane-Wave Sound Field Using an Array of Loudspeakers},
    journal = {IEEE Trans. Speech Audio Process},
    year = {2001},
    volume = {9},
    pages = {697--707}
}

@article{poletti1996_EncodingFunctions,
	title={The Design of Encoding Functions for Stereophonic and Polyphonic Sound Systems},
	author={Poletti, Mark A.},
	journal={J. Audio Eng. Soc},
	volume={44},
	number={11},
	pages={948--963},
	year={1996},
	url={http://www.aes.org/e-lib/browse.cfm?elib=7879},
	abstract={{
Recordings of live performances are often made using coincident microphones, which encode directional information into two or more channels. The accurate reproduction of the performance is dependent on the encoding functions implemented by the coincident microphones. The design of encoding functions is developed for stereophonic, full surround (ambisonic), and semicircular surround systems. An optimum stereo encoding is developed, a family of encoding functions is derived for the ambisonic system, and a method for deriving the optimum encoding functions for semicircular surround systems is introduced.
	}},
	comments={{
		Demuestra de que el minimo de altavoces para un decoding exacto en el centro es 2 * Orden  (N Chanels en 2D). (tambien en poletti2000_UnifiedTheoryHorizontalHolographicSoundSystem) 
	}}
}

# ref 17 es Blauert
# ref 18 sobre psicoacustica Moore
# ref 19 procesado de señal
# ref 20 matlab

@conference{dickins1999towards,
	title={Towards Optimal Soundfield Representation},
	author={Dickins, Glenn and Kennedy, Rodney},
	booktitle={Audio Engineering Society Convention 106},
	month={5},
	year={1999},
	url={http://www.aes.org/e-lib/browse.cfm?elib=8255},
	abstract={{
Conventionally a sound field is characterised by the instantaneous pressure variations in an extended region of space. This paper considers an efficient and general representation of an arbitrary sound field based on a spherical harmonic expansion or modes. It is shown how the Taylor series expansion and the Ambisonics sound field representation can be subsumed into the spherical harmonic expansion description. This clarifies the nature and degree of these common approximations and suggests a more natural and efficient generalization.
	}},
	comments={{
		Describe representaciones: Taylor Multidimensional, Spherical Harmonics y Analisis Modal y comenta las diferencias (numero de canales convergencia...) y mapeos entre ellos.
	}}
}

@conference{bertet2007HOAAcuracyTests,
	title={Investigation of the Perceived Spatial Resolution of Higher Order Ambisonics Sound Fields: A Subjective Evaluation Involving Virtual and Real 3D Microphones},
	author={Bertet, Stéphanie and Daniel, Jérôme and Gros, Laëtitia and Parizet, Etienne and Warusfel, Olivier},
	booktitle={Audio Engineering Society Conference: 30th International Conference: Intelligent Audio Environments},
	month={3},
	year={2007},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13925},
	abstract={{
Natural sound field can be reproduced through loudspeakers using ambisonic and Higher Order Ambisonic (HOA) microphone recordings. The HOA sound field encoding approach is based on spherical harmonics decomposition. The more components used to encode the sound field, the finer the spatial resolution is. As a result of previous studies, two HOA (2nd and 4th order) microphone prototypes have been developed. To evaluate the perceived spatial resolution and encoding artefacts on the horizontal plane, a localisation test was performed comparing these prototypes, a SoundField microphone and a simulated ideal 4th order encoding system. The HOA reproduction system was composed of twelve loudspeakers equally distributed on a circle. Thirteen target positions were chosen around the listener. An adjustment method using an auditory pointer was used to avoid bias effects of usual reporting methods. The human localisation error occurring for each of the tested systems has been compared. A statistical analysis showed significance differences when using the 4th order system, the 2nd order system and the SoundField microphone.
	}},
	comments={{
		Describe tests subjetivos de resolucion angular para diferentes ordenes, micros y reproducción.
		Horizontal plane (aunque ambisonics 3d)
		3rd no mejora significativamente respecto a 2nd pero 4th si.
		Parece que el micro de 32 capsulas va bien para el de 4th
		Background:
			Encoding: numero de sensores necesarios segun orden y limitaciones fisicas
			Diferentes tipos de decoding muy resumidos en que se basan y que aportan, numero minimo de altavoces
			Resolucion angular
			Formas para el sujeto de reportar y limitaciones: azimuth elevacion, puntero visual, referencias, puntero acustico...
	}}
}

@conference{bertet2007investigation,
	title={Investigation of the Perceived Spatial Resolution of Higher Order Ambisonics Sound Fields: A Subjective Evaluation Involving Virtual and Real 3D Microphones},
	author={Bertet, Stéphanie and Daniel, Jérôme and Gros, Laëtitia and Parizet, Etienne and Warusfel, Olivier},
	booktitle={Audio Engineering Society Conference: 30th International Conference: Intelligent Audio Environments},
	month={3},
	year={2007},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13925},
	abstract={{
Natural sound field can be reproduced through loudspeakers using ambisonic and Higher Order Ambisonic (HOA) microphone recordings. The HOA sound field encoding approach is based on spherical harmonics decomposition. The more components used to encode the sound field, the finer the spatial resolution is. As a result of previous studies, two HOA (2nd and 4th order) microphone prototypes have been developed. To evaluate the perceived spatial resolution and encoding artefacts on the horizontal plane, a localisation test was performed comparing these prototypes, a SoundField microphone and a simulated ideal 4th order encoding system. The HOA reproduction system was composed of twelve loudspeakers equally distributed on a circle. Thirteen target positions were chosen around the listener. An adjustment method using an auditory pointer was used to avoid bias effects of usual reporting methods. The human localisation error occurring for each of the tested systems has been compared. A statistical analysis showed significance differences when using the 4th order system, the 2nd order system and the SoundField microphone.
	}},
	comments={{
		Experimentos subjetivos sobre la precision angular en la reproduccion de diferentes tecnicas holograficas
		Contexto:
			HOA: Encoding, decodings (short summary of whys for basic, maxre, inphase)
			Subjective localization estudies (minimal human error), in angle differential depending on orientation
				Localization blur:
				At front +-1º to +-4º depending on kind of source
				Other directions 5.5º to 10º
			Discussion on reporting methods:
				Estimating elevation: long train, judgement errors
				Head tracker: shorter training, but no feedback, time lag, and better behind
				Visual pointers (problem visual-auditory bias)
				Auditory pointer (Pulkki)
		Several configurations for recording the sound field
		Proposes a new way of reporting based on auditory pointer but avoiding biases
		Results:
			Third system does not enhance Second but Fourth does
			Pointing method, has bad performance on non frontal
	}}
}

@article{evans1998_hrtfSphericalHarmonics,
	title = {{Analyzing head-related transfer function measurements using surface spherical harmonics}},
	journal={Journal of the Acoustical Society of America},
	year={1998},
	month={October},
	volume={104},
	number={4},
	author={Evans, Michael J.  and Angus, James A. S. and I. Tew, Anthony},
	url={{http://murphylibrary.uwlax.edu/digital/journals/JASA/JASA1998/pdfs/vol_104/iss_4/2400_1.pdf}},
	abstract={{
A continuous, functional representation of a large set of head-related transfer function measurements (HRTFs) is developed. The HRTFs are represented as a weighted sum of surface spherical harmonics (SSHs) up to degree 17. A Gaussian quadrature method is used to pick out a set of experimentally efficient measurement directions. Anechoic impulse responses are measured for these directions between a source loudspeaker and the entrance to the ear canal of a head-and-torso simulator (HATS). Three separate SSH analyses are carried out: The first forms a SSH representation from the time responses, with the variable onset delay caused by interaural differences intact, by applying the analysis to each time sample in turn. The second SSH model is formed in exactly the same way, except using impulse responses in which the variable onset delays have been equalized. The final SSH analysis is carried out in the frequency domain by applying the technique on a frequency bin by frequency bin basis to the magnitude and unwrapped phase responses of the HRTFs. The accuracy and interpolation performance of each of the computed SSH models is investigated, and the usefulness of the SSH technique in analyzing directional hearing and, particularly, in spatializing sounds is discussed. (C) 1998 Acoustical Society of America. S0001-4966(98)01310-1.
	}},
	comments={{
	}}
}
@conference{abhayapala2007_horizontalPlaneHrtfFourierBessel,
	title={Horizontal Plane HRTF Reproduction Using Continuous Fourier-Bessel Functions},
	author={Abhayapala, Thushara D. and Kennedy, Rodney A. and Zhang, Wen},
	booktitle={Audio Engineering Society Conference: 31st International Conference: New Directions in High Resolution Audio},
	month={6},
	year={2007},
	download={{http://users.cecs.anu.edu.au/~thush/publications/p07_107.pdf}},
	url={http://www.aes.org/e-lib/browse.cfm?elib=13969},
	abstract={{
This paper proposes a method to reproduce the Head Related Transfer Function (HRTF) in the horizontal auditory scene. The method is based on a separable representation which consists of a Fourier Bessel series expansion for the spectral components and a conventional Fourier series expansion for the spatial dependence. The proposed representation can be used to predict HRTFs at any azimuth position and at any frequency sampling point from a finite number of measurements. Implementation details are demonstrated in the paper. Measured HRTFs from a KEMAR manikin and analytically simulated HRTFs were used to validate the fidelity and predictive capabilities of the method. The average mean square error for model reconstruction is less than two percent.
	}},
	comments={{
	}}
}

# Zhang:2009:MEH:1582709.1583835,
@inproceedings{Zhang2009_ModalExpansionHrtf,
	author = {Zhang, Wen and Abhayapala, Thushara D. and Kennedy, Rodney A. and Duraiswami, Ramani},
	title = {Modal expansion of HRTFs: Continuous representation in frequency-range-angle},
	booktitle = {Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
	series = {ICASSP '09},
	year = {2009},
	isbn = {978-1-4244-2353-8},
	pages = {285--288},
	numpages = {4},
	url = {http://dx.doi.org/10.1109/ICASSP.2009.4959576},
	doi = {10.1109/ICASSP.2009.4959576},
	acmid = {1583835},
	publisher = {IEEE Computer Society},
	address = {Washington, DC, USA},
	download = {http://www.umiacs.umd.edu/~ramani/pubs/ZAKD_ICASSP_2009.pdf},
	abstract={{{
This paper proposes a continuous HRTF representation in both 3D spatial and frequency domains. The method is based on the acoustic reciprocity principle and a modal expansion of the wave equation solution to represent the HRTF variations with different variables in separate basis functions. The derived spatial basis modes can achieve HRTF near-field and far-field representation in one formulation. The HRTF frequency components are expanded using Fourier Spherical Bessel series for compact representation. The proposed model can be used to reconstruct HRTFs at any arbitrary position in space and at any frequency point from a finite number of measurements. Analytical simulated and measured HRTFs from a KEMAR are used to validate the model.
	}}},
	comments={{{
	}}}
} 


@article{minimumPhase,
	title={Minimum-phase fir filter design using real cepstrum},
	author={Soo-Chang Pei and Huei-Shan Lin},
	month = {Oct},
	year = {2006},
	volume = {53},
	number = {10},
	pages = {1113--1117},
	download={{http://signal.ee.bilkent.edu.tr/defevent/papers/cr1074.pdf}},
	abstract={{
The real cepstrum is used to design an arbitrary length minimum-phase finite-impulse response filter from a mixed-phase prototype. There is no need to start with the odd-length equiripple linear-phase filter first. Neither the phase-unwrapping nor root-finding procedure is needed. Only two fast Fourier transforms and a recursive procedure are required to find the filter's impulse response from its real cepstrum. The resulting filter's magnitude response is exactly the same as the original one even when the filter is of very high order
	}},
	comments={{
		Explains an optimal algorithm to get the Minimum-Phase filter.
		Nice visual examples of the construction process.
	}}
}


@inproceedings{LearningBinauralCues,
	url = {http://www.scientificcommons.org/20698455},
	title = {Auditory learning with binaural cues to localisation},
	author = {Ellis, W. and Rowan, D.},
	year = {2006},
	booktitle = {{BSA Short Papers Meeting on Experimental Studies of Hearing and Deafness}},
	address = {London, UK},
	month = {September},
	keywords = {RF Otorhinolaryngology, TA Engineering (General). Civil engineering (General)},
	abstract = {The performance of normal–hearing humans on various auditory discrimination tasks improves with multi–hour practice/training; that is ‘learning’ takes place. However, few studies have investigated this learning for binaural cues over earphones. On the basis of an initial experiment, Wright & Fitzgerald (2001) argued that low–frequency ITD discrimination is not influenced by multi–hour training in general whereas high–frequency ILD discrimination is influenced by multi–hour training. They suggested that the implied difference in time–course between cues may be related to known differences in brain stem processing. However, a subsequent experiment by Rowan & Lutman (2005) indicated, in contrast, that multi–hour training did lead to learning with ITD and at both low and high frequencies, with time–courses that were at least broadly comparable to Wright & Fitzgerald’s (2001) data on ILD. However, potentially important differences in methodologies between the two studies complicate comparisons of learning. The primary aim of the present study was to estimate the time-course of learning on ILD using Rowan & Lutman’s (2005) general methodology to enable a more direct comparison of the time courses between ILD and ITD. Twelve naïve listeners participated in this experiment. ILD thresholds were measured using a forced choice task combined with an adaptive procedure. Thresholds at 128 Hz and 4000 Hz were measured with all listeners during pre and post test sessions, nominally separated by 11 days. Between pre and post tests, six listeners received training consisting of repeated measurements at 4000 Hz only over 6 separate days amounting to 2160 trials; the others served as untrained controls. ILD thresholds at the trained frequency (4000 Hz) were found to reduce between pre and post test in both groups but the trained group learned significantly more than untrained group. The time-course of learning appeared broadly comparable with that found by Rowan & Lutman (2005) with low and high–frequency ITD and Wright & Fitzgerald (2001) with ILD at high–frequency. The implications of these results and suggestions for more detailed statistical investigations of time-course of learning will be discussed.},
	publisher = {British Society of Audiology},
	institution = {e-Prints Soton [http://eprints.soton.ac.uk/perl/oai2] (United Kingdom)},
	comment = {{Learning }}
}

@article{LearningNewPinna,
    author = {Van Wanrooij, Marc M. and Van Opstal, A. John},
    title = {{Relearning sound localization with a new ear.}},
    abstract = {{
                Human sound localization results primarily from the processing of binaural differences in sound level and arrival time for locations in the horizontal plane (azimuth) and of spectral shape cues generated by the head and pinnae for positions in the vertical plane (elevation). The latter mechanism incorporates two processing stages: a spectral-to-spatial mapping stage and a binaural weighting stage that determines the contribution of each ear to perceived elevation as function of sound azimuth. We demonstrated recently that binaural pinna molds virtually abolish the ability to localize sound-source elevation, but, after several weeks, subjects regained normal localization performance. It is not clear which processing stage underlies this remarkable plasticity, because the auditory system could have learned the new spectral cues separately for each ear (spatial-mapping adaptation) or for one ear only, while extending its contribution into the contralateral hemifield (binaural-weighting adaptation). To dissociate these possibilities, we applied a long-term monaural spectral perturbation in 13 subjects. Our results show that, in eight experiments, listeners learned to localize accurately with new spectral cues that differed substantially from those provided by their own ears. Interestingly, five subjects, whose spectral cues were not sufficiently perturbed, never yielded stable localization performance. Our findings indicate that the analysis of spectral cues may involve a correlation process between the sensory input and a stored spectral representation of the subject's ears and that learning acts predominantly at a spectral-to-spatial mapping level rather than at the level of binaural weighting.
            }},
    citeulike-article-id = {1610696},
    citeulike-linkout-0 = {http://dx.doi.org/10.1523/JNEUROSCI.0850-05.2005},
    citeulike-linkout-1 = {http://www.jneurosci.org/cgi/content/abstract/25/22/5413},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/15930391},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=15930391},
    day = {1},
    doi = {10.1523/JNEUROSCI.0850-05.2005},
    issn = {1529-2401},
    journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
    keywords = {ear, external, hearing, localization, pinna},
    month = jun,
    number = {22},
    pages = {5413--5424},
    pmid = {15930391},
    posted-at = {2012-06-07 15:16:27},
    priority = {2},
    url = {http://dx.doi.org/10.1523/JNEUROSCI.0850-05.2005},
    volume = {25},
    year = {2005},
	download = {{}},
}

@article{minimumAudibleAngle,
	title={On the Minimum Audible Angle},
	author={Wills, A. W.},
	journal={{Journal Acoustical Society of America}},
	number=30,
	volume=4,
	pages={237-246},
	year=1958,
	doi={10.1121/1.1909553},
	url={{http://asadl.org/jasa/resource/1/jasman/v30/i4/p237_s1}},
	abstract={{
		The difference limen for the azimuth of a source of pure tones was measured as a function of the frequency of the tone and the direction of the source. Tone pulses between 250 and 10 000 cps were sounded in the horizontal plane around the head of a subject seated in an anechoic chamber. The smallest angular separation that can be detected between the sources of two successive tone pulses (the minimum audible angle) was determined for each of three subjects. These threshold angles are analyzed in terms of the corresponding threshold changes in the phase, time, and intensity of the tone at the ears of the subject. A comparison of these thresholds with those reported for dichotic stimulation indicates that the resolution of the direction of a source is determined, at frequencies below about 1400 cps, by interaural differences in phase or time, and at higher frequencies by differences in intensity. When the conditions are optimal for temporal discrimination, the threshold for an interaural difference in time is about 10μsec, and when the conditions are optimal for intensity discrimination, the threshold for an interaural difference in intensity is about 0.5 db.
	}},
	comment={{
		Original definition of the minimum Audible Angle method.
		Later uses and a refinement is Morris-Rakerd
		http://www.pa.msu.edu/acoustics/maa.pdf
	}}
}


@article{shinn_cunningham_2000_toriconfusion,
	title={Tori of confusion: binaural localization cues for sources within reach of a listener.},
	author={Shinn-Cunningham, B.G. and Santarelli, S. and Kopco, N.},
	journal={J Acoust Soc Am},
	volume={107},
	number={3},
	pages={1627-36},
	year={2000},
	download = {{http://cns-web.bu.edu/~shinn/pages/pdf/JASA_Tori.pdf}},
	abstract={To a first-order approximation, binaural localization cues are ambiguous: many source locations give rise to nearly the same interaural differences. For sources more than a meter away, binaural localization cues are approximately equal for any source on a cone centered on the interaural axis (i.e., the well-known "cone of confusion"). The current paper analyzes simple geometric approximations of a head to gain insight into localization performance for nearby sources. If the head is treated as a rigid, perfect sphere, interaural intensity differences (IIDs) can be broken down into two main components. One component depends on the head shadow and is constant along the cone of confusion (and covaries with the interaural time difference, or ITD). The other component depends only on the relative path lengths from the source to the two ears and is roughly constant for a sphere centered on the interaural axis. This second factor is large enough to be perceptible only when sources are within one or two meters of the listener. Results are not dramatically different if one assumes that the ears are separated by 160 deg along the surface of the sphere (rather than diametrically opposite one another). Thus for nearby sources, binaural information should allow listeners to locate sources within a volume around a circle centered on the interaural axis on a "torus of confusion." The volume of the torus of confusion increases as the source approaches the median plane, degenerating to a volume around the median plane in the limit. },
	comment ={{
			Extends the concept of cone of confusion
	}}
}

@article{feddersen57,
	title = {{Localization of High-Frequency Tones}},
	author = {Feddersen, W. E. and Sandel, T. T. and Teas, D. C. and Jeffress, L. A.},
	day = {01},
	month = sep,
	year = {1957},
	journal = {{The Journal of the Acoustical Society of America}},
	volume = {29},
	number = {9},
	pages = {988--991},
	doi = {10.1121/1.1909356},
	keywords = {binaural, itd, psychophysics},
	publisher = {Acoustical Society of America},
	url = {http://dx.doi.org/10.1121/1.1909356},
	citeulike-article-id = {10477008},
	citeulike-linkout-0 = {http://dx.doi.org/10.1121/1.1909356},
	abstract = {{In an earlier study, [Sandel, Teas, Fedderson, and Jeffress, J. Acoust. Soc. Am. 27, 842 (1955)] the writers attempted to correlate interaural intensity and time differences with the subject's localization response. The present paper is an extension of that work. It includes physical measurements of interaural time differences and intensity differences, and attempts to relate these differences to the localization response at a variety of frequencies. The stimuli to be localized were provided through earphones, and the subject was required to match the position (in his head) of a noise and a tone. The noise to one ear was delayed, and the tone presented with no time or phase difference. The subject adjusted the interaural level of the tone until it and the noise appeared to be in the same place. The two were presented alternately by means of a gate having a 150‐msec rise and decay time.Data from the localization judgments were then compared with the findings from the acoustical measurements of time and intensity. Several systematic trends were found and compared with results of the previous study.}},
	comment={{
		Study on the frequency dependency of the effectiveness of ITD and ILD localization cues.
	}}
}

@article{minimumAduditoryMovementAngle,
	author = {Perrot, D. R. and Musicant, A. D.},
	title = {{Minimum auditory movement angle : Binaural localization of moving sound sources}},
	journal = {The Journal of the Acoustical Society of America},
	year = {1977},
	volume = {62},
	number = {6},
	pages = {1463--1466},
	keywords = {computational-acoustics},
	posted-at = {2011-07-26 06:07:13},
	priority = {3},
	citeulike-article-id = {9579907},
	download={{}},
	comment = {{
		Studying moving source effect on localization, and perceiving movement
		TODO: Conclusions summary
	}}
}

@inproceedings{localizationOfFamiliarSounds,
	author= {{ G. Plenge, and G.Brunschen}},
	year=1971,
	title = {Signalkenntnis und Richtungsbestimmung in der Medianebene bei Sprache},
	booktitle ={{Proceedings of the 7th International Congress on Acoustics}},
	_editor={International Union of Pure and Applied Physics. International Commission on Acoustics and international Congress on Acoustics},
	publisher={Akad{\'e}miai Kiad{\'o}},
	address ={{Budapest, 19 H10}},
	comment = {{
		Translated title: A priori knowledge of the signal when determining the direction of speech in the median plane.
		Referenced by Blauert and others no electronic access
		Experiment: Known human voices were better localized along the median plane than unknown voices.
	}}

}

@article{Wallach1940Role,
	author = {Wallach, Hans},
	title = {{The role of head movements and vestibular and visual cues in sound localization}},
	keywords = {localization, psych},
	year = {1940},
	journal = {Journal of Experimental Psychology},
	volume = {27},
	number = {4},
	pages = {339--368},
	abstract = {{Experiments of synthetic production of sound directions are reported which show that either vestibular cues or visual cues can replace head movements as such. In one group of experiments the blindfolded subject localized the sound while he was passively turned on a revolving chair, and in the other group the subject observed the direction of sound while seated inside a revolving screen. The results indicate that (1) fairly accurate representation of the actual displacement of the head is furnished by vestibular stimulation and that (2) visual stimulation, equivalent to that which actual displacement of the head would give, suffices to determine the direction of sound.}},
	citeulike-article-id = {2389214},
	posted-at = {2008-02-16 22:19:54},
	priority = {0},
	download = {{{http://wexler.free.fr/library/files/wallach\%20(1940)\%20the\%20role\%20of\%20head\%20movements\%20and\%20vestibular\%20and\%20visual\%20cues\%20in\\%20sound\%20localization.pdf
	}}},
	comment = {{
		User experiments:
			Head movements improves localization 
			Visual cues improves localization
			Vestibular system is also used
	}}
}

@article{Begault1992Perceptual,
	abstract = {{A psychoacoustic investigation was conducted in which five subjects gave localization judgments for headphone-delivered speech stimuli processed by nonindividual head-related transfer functions, with and without synthetic "spatial" reverberation added to the stimuli. Spatial reverberation minimized intracranially heard stimuli, but increased the magnitude of azimuth and elevation localization errors. The results are applicable to three-dimensional sound systems and spatial sound field processors designed to increase the sensation of auditory "spaciousness."}},
	author = {Begault, Durand R.},
	citeulike-article-id = {5205669},
	citeulike-linkout-0 = {http://www.aes.org/e-lib/browse.cfm?elib=7027},
	journal = {Journal of the Audio Engineering Society},
	keywords = {localization, psych, reverb},
	month = nov,
	number = {11},
	pages = {895--904},
	posted-at = {2009-07-19 23:29:02},
	priority = {2},
	title = {{Perceptual Effects of Synthetic Reverberation on Three-Dimensional Audio Systems}},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=7027},
	volume = {40},
	year = {1992},
	comment = {{
		Study on psychoacoustics of introducing synthetic reverberations
			Helps to reduce intracraneal heard stimuli
			Generates more errors in localization
		}}
}


@article{KatoMasaharu_200309,
	author="Kato Masaharu and Uematsu Hisashi and Kashino Makio and Hirahara Tatsuya",
	title="The effect of head motion on the accuracy of sound localization",
	journal="Acoustical science and technology",
	ISSN="13463969",
	publisher="The Acoustical Society of Japan (ASJ)",
	year="2003",
	month={{September}},
	volume="24",
	number="5",
	pages="315-317",
	URL="http://ci.nii.ac.jp/naid/110003102831/en/",
	DOI="10.1250/ast.24.315",
	keywords = {{Sound localization, Head motion, HRTFs, Individual differences}},
	download = {{}},
	abstract = {{
			
		}},
	comment={{
		head movements can overcome a change of pina (filled with plastic)
		left right movements compensate better than up down
		Ojo!! puede ser una pulga sin patas:
			(si solo dejas los interaurals solo afectan los interaurals)
			Up-down deja en el mismo cono de confusion para ITD y ILD
			Faltaria una prueba de up-down vs left-right sin relleno
	}}
}




@conference{griesinger1990binaural,
	title={Binaural Techniques for Music Reproduction},
	author={Griesinger, David},
	booktitle={Audio Engineering Society Conference: 8th International Conference: The Sound of Audio},
	month={5},
	year={1990},
	url={http://www.aes.org/e-lib/browse.cfm?elib=5415},
	abstract = {{
		Binaural recording and signal processing are generating boundless enthusiasm in the audio press these days, potentially offering perfect surround from only two loudspeakers, incredible earphone reproduction, etc. Yet the physics of binaural hearing and the enormous differences in ear shape between different individuals present possibly insurmountable barriers to these goals. This paper will review the principals of binaural hearing, and use the results of our own research and that of many others to describe just how high these barriers are. We will then show a few ways they can be bypassed or worked around. Our own research goals at Lexicon are binaural recording techniques which are at least as effective for two channel loudspeaker reproduction as standard miking, improved performance from loudspeaker stereo, and headphone equalization which allows the full benefits of binaural recording to be enjoyed by a large fraction of interested listeners.
	}},
	comment = {{
		Binaural recording TODO: Which one
		Equalization to make it widespread
	}},
}

@article{PerrettNoble1997,
	title={{The effect of head rotations on vertical plane sound localization}},
	author = {{Perrett, S. and Noble, W.}},
	journal={{Journal Acoustical Society of America}},
	volume = 102,
	number = 4,
	pages = {{2325–2332}},
	year = 1997,
	abstract = {{
		Current understanding gives predominant weight to stationary cues for auditory localization. Two experiments were conducted to investigate the possible existence of a dynamic cue. The first experiment involved localization of concealed sources in the upper median vertical plane (MVP) and showed, as expected, that elevation was not detectable with motionless listening when high-frequency energy was absent or when normal pinna function was distorted. Elevation under such conditions did become detectable with horizontal head rotations, provided low-frequency energy was present in the signal. This indicates that the basis of the dynamic cue is variation in the rate of transformation of low-frequency interaural time/phase differences. The second experiment involved localization of sources arrayed throughout upper and lower regions of the MVP and in the left lateral vertical plane (LVP); it showed that upper hemisphere sources can be distinguished somewhat from those in the lower hemisphere, even in motionless listening conditions, but more so with rotation. The greatest benefit for localization from rotation of the head appears to be gained for sources positioned in the front MVP.
		}},
	comment = {{
		Not found a copy
		Head rotations on localization
		ILD and ITD, median plane, back-front-up-down confusions
		Uses frequency to stress either ILD or ITD
		From the abstract:
			Median vertical plane, no high frequencies or distorted pinna
				motionless hard to infer elevation,
				horizontal motion plus low freqs ok
				conclusion ITD variation rate gives elevation.
			Left lateral vertical plane
				no movement needed to diferentiate up downa
				with rotation better
				rotation provides better increase on front MVP
		}}
}

@conference{begault2000direct,
	title={Direct Comparison of the Impact of Head Tracking, Reverberation, and Individualized Head-Related Transfer Functions on the Spatial Perception of a Virtual Speech Source},
	author={Begault, Durand R.; Lee, Alexandra S.; Wenzel, Elizabeth M.; Anderson, Mark R.},
	booktitle={Audio Engineering Society Convention 108},
	month={2},
	year={2000},
	url={http://www.aes.org/e-lib/browse.cfm?elib=9204},
	download = {{http://human-factors.arc.nasa.gov/publications/Begault_2000_Head_Tracking_Impact_Comparison.pdf}},
	abstract = {{
		A study was performed using headphone-delivered virtual speech stimuli, rendered via HRTF-based acoustic auralization software and hardware as well as blocked-meatus HRTF measurements. The independent variables were chosen to evaluate commonly held assumptions in the literature regarding improved localization: inclusion of head tracking, individualized HRTFs, and early and diffuse reflections. Significant differences were found for azimuth/elevation error, reversal rates, and externalization.
	}},
	comment = {{
		Paper version begault2001direct
	}}

}
@article{begault2001direct,
	title={Direct Comparison of the Impact of Head Tracking, Reverberation, and Individualized Head-Related Transfer Functions on the Spatial Perception of a Virtual Speech Source},
	author={Begault, Durand R. and Wenzel, Elizabeth M. and Anderson, Mark R.},
	journal={J. Audio Eng. Soc},
	volume={49},
	number={10},
	pages={904--916},
	year={2001},
	url={http://www.aes.org/e-lib/browse.cfm?elib=10175},
	abstract = {{
		A study of sound localization performance was conducted using headphone-delivered virtual speech stimuli, rendered via HRTF-based acoustic auralization software and hardware, and blocked-meatus HRTF measurements. The independent variables were chosen to evaluate commonly held assumptions in the literature regarding improved localization: inclusion of head tracking, individualized HRTFs, and early and diffuse reflections. Significant effects were found for azimuth and elevation error, reversal rates, and externalization.
	}},
	comment = {{
		Free digitally available just the conference version begault2000direct
		More from author in http://human-factors.arc.nasa.gov/organization/personnel_view.php?personnel_id=16
	}}
}

@article{Wightman1999,
	author = {Wightman, F.~L. and Kistler, D.~J.},
	title = {Resolution of front-back ambiguity in spatial hearing by listener and source movement},
	journal = {Acoustical Society of America Journal},
	year = 1999,
	month = may,
	volume = 105,
	pages = {2841-2853},
	doi = {10.1121/1.426899},
	adsurl = {http://adsabs.harvard.edu/abs/1999ASAJ..105.2841W},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	abstract = {{
		Normally, the apparent position of a sound source corresponds closely to its actual position. However, in some experimental situations listeners make large errors, such as indicating that a source in the frontal hemifield appears to be in the rear hemifield, or vice versa. These front–back confusions are thought to be a result of the inherent ambiguity of the primary interaural difference cues, interaural time difference (ITD) in particular. A given ITD could have been produced by a sound source anywhere on the so-called “cone of confusion.” More than 50 years ago Wallach [J. Exp. Psychol. 27, 339–368 (1940)] argued that small head movements could provide the information necessary to resolve the ambiguity. The direction of the change in ITD that accompanies a head rotation is an unambiguous indicator of the proper hemifield. The experiments reported here are a modern test of Wallach’s hypothesis. Listeners indicated the apparent positions of real and virtual sound sources in conditions in which head movements were either restricted or encouraged. The front–back confusions made in the restricted condition nearly disappeared in the condition in which head movements were encouraged. In a second experiment head movements were restricted, but the sound source was moved, either by the experimenter or by the listener. Only when the listener moved the sound source did front–back confusions disappear. The results clearly support Wallach’s hypothesis and suggest further that head movements are not required to produce the dynamic cues needed to resolve front–back ambiguity.
	}},
	comment = {{
		User tests with restricted and not restricted movements and also source movements
		Source movements help to disambiguate front-back ambiguity as do head movements
	}}
}


@article{Wenzel1988personalHrtf,
	author = {Wenzel, E. and Wightman F and Kistler D.},
	title = "{Acoustic origins of individual differences in sound localization behavior}",
	journal = {Acoustical Society of America Journal},
	year = 1988,
	month = jul,
	volume = 84,
	pages = {79},
	doi = {10.1121/1.2026486},
	adsurl = {http://adsabs.harvard.edu/abs/1988ASAJ...84...79W},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	comment = {{
		Sensible to nonindividualized HRTF
	}}
}

@article{Wenzel1993,
	journal = {J Acoust Soc Am.},
	year = 1993,
	month = jul,
	volume = 94,
	number = 1,
	pages = {111-23},
	title = {Localization using nonindividualized head-related transfer functions.},
	author = {Wenzel, EM and Arruda, M and  Kistler, DJ and Wightman, FL.]},
	download={{http://human-factors.arc.nasa.gov/publications/wenzel_1993_Localization_Head_Related.pdf}},
	abstract = {{
		A recent development in human-computer interfaces is the virtual acoustic display, a device that synthesizes three-dimensional, spatial auditory information over headphones using digital filters constructed from head-related transfer functions (HRTFs). The utility of such a display depends on the accuracy with which listeners can localize virtual sound sources. A previous study [F. L. Wightman and D. J. Kistler, J. Acoust. Soc. Am. 85, 868-878 (1989)] observed accurate localization by listeners for free-field sources and for virtual sources generated from the subjects' own HRTFs. In practice, measurement of the HRTFs of each potential user of a spatial auditory display may not be feasible. Thus, a critical research question is whether listeners can obtain adequate localization cues from stimuli based on nonindividualized transforms. Here, inexperienced listeners judged the apparent direction (azimuth and elevation) of wideband noisebursts presented in the free-field or over headphones; headphone stimuli were synthesized using HRTFs from a representative subject of Wightman and Kistler. When confusions were resolved, localization of virtual sources was quite accurate and comparable to the free-field sources for 12 of the 16 subjects. Of the remaining subjects, 2 showed poor elevation accuracy in both stimulus conditions, and 2 showed degraded elevation accuracy with virtual sources. Many of the listeners also showed high rates of front-back and up-down confusions that increased significantly for virtual sources compared to the free-field stimuli. These data suggest that while the interaural cues to horizontal location are robust, the spectral cues considered important for resolving location along a particular cone-of-confusion are distorted by a synthesis process that uses nonindividualized HRTFs.
	}},
	comment = {{
		Nonindividualized HRTF
			mess cone of confusion
			mess elevation
			solid interaural cues
	}}
}


@article{Brown_SphereHrtfs,
	author={{C. Phillip Brown and Richard O. Duda}},
	title= {{A Structural Model for Binaural Sound Synthesis}},
	journal = {IEEE Transactions on Speech and Audio Processing},
	volume = {6},
	number = {5},
	year = {1998},
	pages = {476-488},
	doi = {10.1109/89.709673},
	url = {{http://interface.cipic.ucdavis.edu/PAPERS/Brown1997(Efficient3dHRTFModels).pdf}},
	abstract = {{
A structural model is presented for synthesizing
binaural sound from a monaural source. The model produces
well-controlled vertical as well as horizontal effects. The model is
based on a simplified time-domain description of the physics of
wave propagation and diffraction. The components of the model
have a one-to-one correspondence with the physical sources of
sound diffraction, delay, and reflection. The simplicity of the
model permits efficient implementation in DSP hardware, and
thus facilitates real-time operation. Additionally, the parameters
in the model can be adjusted to fit a particular individual’s
characteristics, thereby producing individualized head-related
transfer functions. Experimental tests verify the perceptual ef-
fectiveness of the approach.
	}},
	keywords = {{Binaural, head-related transfer functions, localization, spatial hearing, 3-D sound, virtual auditory space.
	}},
	comment = {{
		They model parametrized HRTF's based on a time domain model similar to the one we use for analytical.
		They simplify the head to a sphere and provide formulas 	
	}}
}


# Source spatial extend

@phdthesis{potard2006_thesis,
	title={3D-audio object oriented coding},
	author={Potard, G.},
	school={University of Wollongong},
	booktitle={University of Wollongong Thesis Collection},
	pages={539},
	year={2006},
	download={{{http://ro.uow.edu.au/cgi/viewcontent.cgi?filename=0&article=1539&context=theses&type=additional}}},
	comment = {{
		Wideness and shape perception depending on many parameters
		Nice introduction to perception
	}}
}

@inproceedings{potard2003_studyApparentShapeAndWideness,
	title = {A study on sound source apparent shape and wideness},
	booktitle = {Proceedings of the 9th International Conference on Auditory Display (ICAD2003)},
	editor = {Brazil, E. and Shinn-Cunningham, B.},
	year = {2003},
	pages = {25-28},
	publisher = {Boston University Publications Production Department},
	organization = {Boston University Publications Production Department},
	address = {Boston, USA},
	abstract = {This work is intended as an initial investigation into the perception of wideness and shape of sound sources. A method that employs multiple uncorrelated point sources is used in order to form ``sound shapes''. Several experiments were carried out in which, after some initial training, subjects were asked to indentify the shapes that were being played. Results indicate that differences in vertical and horizontal source wideness are easily perceived and scenes that use broad sound sources to represent normally large sound objects are selected 70% of the time over point source versions. However, shape identification was found to be more ambiguous except for certain types of signals where results were above statistical probability. The work indicates that shape and wideness of sound sources could be effectively used as extra cues in virtual auditory displays and generally improve the realism of virtual 3D sound scenes. This work was performed as a Core Experiment within the MPEG Audio Subgroup with the intention of possible integration of source wideness into MPEG-4 AudioBIFS.},
	download = {http://icad.org/Proceedings/2003/PotardBurnett2003.pdf},
	author = {Potard, G. and Burnett, I.},
	comment = {{{
		What can be perceived and what cannot.
		Shape quite limited with exceptions
		Horizontal and vertical extent quite precise
		Wide sources build more natural scenes
	}}}
}


@article{rich1916_tonalVolume,
	title={{A preliminary study of tonal volume}},
	author={{Rich, G. J.}},
	journal = {{Journal of Experimental Psychology}},
	volume = 1,
	number = 1,
	month = Feb,
	year = 1916,
	pages = {13-22},
	doi = {{10.1037/h0065683}},
	abstract = {{
		Reports findings from an experiment that show: judgments of tonal volume can be made with ease, and with as great consistency as is usual for attributive judgments; the judgments may be made on an attributive basis--after secondary criteria have been eliminated, by practice, they are as immediate as judgments of pitch; within the limits of the experiment, the relative difference limen of tonal volume is approximately constant; and this limen is different from that of pitch, both in magnitude and in course.
		}},
	comments = {{
		Reported as the first reference to 'tonal volume' as measure for source extent.
	}}
}

@inproceedings{potard2004_decorrelationSourceWidth,
	booktitle = { Proceedings of the 7th International Conference on Digital Audio Effects DAFX04},
	address = {Naples, Italy},
	year = 2004,
	month = {October},
	title = {Decorrelation techniques for the rendering of apparent sound source width in 3D audio displays},
	author = {Potard, Guillaume and Burnett, Ian},
	abstract = {{
		The aim of this paper is to give an overview of the techniques and principles for rendering the apparent source extent of sound sources in 3D audio displays. We mainly focus on techniques that use decorrelation as a mean to decrease the Interaural Cross-Correlation Coefficient (IACC) which has a direct impact on the perceived source extent. We then present techniques where decorrelation is varied in time and frequency, allowing to create tempo­ ral and spectral variations in the spatial extent of sound sources.  Frequency dependant decorrelation can be employed to create an effect where a sound is spatially split in its different frequency bands, these having different positions and spatial extents. We fi nally present results of psychoacoustic experiments aimed at evaluating the effectiveness of decorrelation based techniques for the rendering of sound source extent. We found that the intended source extent matches well the mean perceived source extent by subjects.
	}},
	download = {{http://dafx04.na.infn.it/WebProc/Proc/P_280.pdf}},
	comments = {{
		How to use decorrelation to control the extent of sources by means of inter-aural correlation coefficient
		Nice Density plots of source extent perception
		Test procedure subject to errors but just demonstrate that there is something like extent perception at the intended zones
	}},
}

@article{boring1926,
	title = {{Auditory theory with special reference to intensity, volume and localization.}},
	author = {{Boring, E. G.}},
	journal = {{The American Journal of Psychology}},
	volume = 37,
	year = 1926,
	pages = {157-188},
	doi = {10.2307/1413687},
	abstract = {{
		The physiological mechanism of hearing is considered in a general way, without proposing any specific theory, with special relation to the facts of auditory intensity, volume and localization. In order to explain the greatest possible number of facts, a "frequency-theory" is adopted, in which quality is correlated with frequency and intensity with the number of specific nerve fibres stimulated. Intensive summation then requires some sort of integration in the brain, probably an excitory dispersion similar to Bernstein's theory. The direct correlate of auditory intensity is the amplitude of the stimulus. The experimentally determined relationship between intensity and volume shows that degree of excitation and dispersion are related as would be expected, while the relation of volume and pitch is explained as due to lack of control of amplitude. The principle of cortical dispersion, combined with the assumption that the fibers from the two ears are distributed to adjacent regions of the brain, explains the phenomena of the intensity-theory of localization of sound, while the additional mechanism of inhibition reduces the time-theory to the intensity-theory and an appeal to the all-or-none law subsumes the phase-theory under the time-theory. Tonal volume is considered as a pre-spatial attribute. The problem which Ohm's law sets for a frequency-theory of pitch lacks a satisfactory solution at present. The refractory period of nervous excitation also presents difficulties, but there is reason to believe, in the absence of direct evidence, that it is short enough to account for the range of audible tones. The argument from tonal lacunae is not fatal to a frequency-theory, because the evidence for their existence is not at present conclusive.
	}},
	comments = {{{
		Referenced by potard2006_thesis as first study on 'tonal volume' (perceived source size)
	}}}
}

@article{Stevens1934,
	title = {{The volume and intensity of tones.}},
	author = {{Stevens, S. S.}},
	journal = {{American Journal of Psychology}},
	volume = 46,
	year = 1934,
	pages = {397-408},
	doi = {10.2307/1415591},
	download = {{{}}},
	abstract = {{{
	}}},
	content = {{{
		Not retrieved referenced by potard2006_thesis
		Tonal volume, by transdimensional scaling, separate sound source attribute, but affected with loudness and pitch
	}}}
}

@article{GuiraoStevens1964,
	author = {{M. Guirao and S. S. Stevens}},
	title = {{Measurement of auditory density}},
	journal = {{Journal of the Acoustical Society of America}},
	volume = 36,
	number = 6,
	pages = {{1176–1182}},
	year = 1964,
	abstract = {{{
	}}},
	content = {{{
		Not retrieved referenced by potard2006_thesis
		Defines 'Auditory density': 
		In pure tones increases with with frequency
	}}}
}

@article{PerrotBuell1982,
	author = {{D. R. Perrott and T. N. Buell}},
	title = {{Judgments of sound volume: Effects of signal duration, level, and interaural characteristics on the perceived extensity of broadband noise.}},
	journal = {{Journal of the Acoustical Society of America}},
	volume = 72,
	number = 5,
	pages = {1413–1417},
	year = 1982,
	doi = {10.1121/1.388447},
	abstract = {{{
		While auditory stimuli are often described in terms of their apparent extensity, such descriptions have usually not been collected systematically. Moreover, the few deliberate attempts to evaluate image size have rarely gone beyond the classic parameters of stimulus frequency and intensity. In the present study a direct magnitude estimation procedure was employed. Seventeen subjects numerically estimated the apparent size of images produced by broadband noise stimuli. Under earphone listening conditions, signals were presented either dichotically (uncorrelated noise), diotically (correlated noise), or monaurally (noise led to a single earphone). The signals in each of these modes varied in duration (100, 300, 1000, and 3000 msec) and intensity level (60, 75, and 90 dB A weighted). Size estimates were plotted as power functions and analyzed with a repeated measures design analysis of variance. Consistent with previous research, the main effects of duration and intensity were both highly significant (p less than 0.001). In addition, a highly significant effect for mode of presentation was found (p less than 0.001). Across conditions, dichotic stimulation produced the largest images and monaural stimulation the smallest (about half the size of the diotic images). This last result is the first quantification of previous anecdotal observations. General implications of these results were discussed.
	}}},
	content = {{{
		Not retrieved cited by potard2006_thesis
		Perceived size decreases on pure tone with frequency, equal perceived loudness
	}}}
}




@article{Algazi2001_lowFrequencyElevationCues,
	title = {{Elevation localization and head-related transfer function analysis at low frequencies}},
	author = {Algazi, V. R. and Avendano, C. and Duda, R. O.},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {free-field-stimuli, hrtfhrir, hrtfhrir-modelsimplification, initial-uberbib-import, localisation},
	pages = {1110-1122},
	volume = 109,
	number = 3,
	year = {2001},
	download = {{{http://interface.cipic.ucdavis.edu/pubs/JAS_Mar_2001.pdf}}},
	abstract = {{
		Monaural spectral features due to pinna diffraction are the primary cues for elevation. Because these
features appear above 3 kHz where the wavelength becomes comparable to pinna size, it is generally
believed that accurate elevation estimation requires wideband sources. However, psychoacoustic
tests show that subjects can estimate elevation for low-frequency sources. In the experiments
reported, random noise bursts low-pass filtered to 3 kHz were processed with individualized
head-related transfer functions ͑HRTFs͒, and six subjects were asked to report the elevation angle
around four cones of confusion. The accuracy in estimating elevation was degraded when compared
to a baseline test with wideband stimuli. The reduction in performance was a function of azimuth
and was highest in the median plane. However, when the source was located away from the median
plane, subjects were able to estimate elevation, often with surprisingly good accuracy. Analysis of
the HRTFs reveals the existence of elevation-dependent features at low frequencies. The physical
origin of the low-frequency features is attributed primarily to head diffraction and torso reflections.
It is shown that simple geometrical approximations and models of the head and torso explain these
low-frequency features and the corresponding elevations cues. © 2001 Acoustical Society of
America. ͓DOI: 10.1121/1.1349185͔
	}},
	comment = {{
		How elevation on low frequencies is perceived
		Because of size pinna just can have influence above 3kHz
		User tests demonstrated that can be localized
			Not in the median plane
		KEMAR measured HRTF analysis changing pinna and body
		Conclusion: Torso reflections and head refraction introduces those cues
		Introduces a simplified parametric model of the torso which matches spectral cues
	}}
}

@inproceedings{Batteau1967_pinna,
	author = {{D. W. Batteau}},
	title = {{The role of the pinna in human sound localization}},
	booktitle = {{Proceedings of Royal Society}},
	volume =  168,
	pages = {158–180},
	year = 1967,
	comment = {{{
		According to potard2006_thesis, the first one to say Rayleigh is not enough
	}}}
}

@inproceedings{Neuhoff2001_sourceOrientation,
	author = {{Neuhoff, J. G.}},
	title = {{Perceiving acoustic source orientation in three-dimensional space}},
	booktitle = {{Proceedings of International Conference on Auditory Display, 2001}},
	year = 2001,
	address = {{Espoo, Findland}},
	download = {{http://www.icad.org/Proceedings/2001/Neuhoff2001.pdf}},
	comment = {{
		According to potard2006_thesis
		Perception: Source Orientation
		Rotation when the source has non constant directivity pattern
		Easier to detect in front
		Easier to detect when rotating (dynamic)
		Easier to dectect when close distance
	}}
}

@article{FaragBlauerAlim2003_sourceOcclusion,
	author = { H. Farag and J. Blauert and O. Abdel Alims},
	title = {{Psychoacoustic investigations on sound-source occlusion}},
	journal = {{Journal of the Audio Engineering Society}},
	volume = 51,
	number = {7/8},
	pages = {635–646},
	year = 2003,
	abstract = {{{
		Efficient simulation of sound-source occlusion is needed, for example, in auditory virtual environments, and remains an interesting and at present not widely researched topic. In order to achieve plausible and efficient simulation, the changes in psychoacoustical parameters accompanying the perception of sound-source occlusion have to be identified and understood. The impact of occlusion on the localization of auditory events is investigated with the aid of listening tests. Rectangular wood plates of different dimensions are used as occluders. A noticeable shift in the location of the auditory events is observed. The results can be explained on grounds of the precedence effect.
	}}},
	comments = {{{
		Not retrieved
		According to potard2006_thesis
		Perception: Source occlusion
		Depending on the size of the obstacle diffraction or attenuation of the direct sound
		Diffraction generates a shift in perceived source position towards the borders of the obstacle
	}}}
}


@article{OldfieldParker1984_acuityNormal,
	author = {Oldfield, S R and Parker, S P},
	title = {Acuity of sound localisation: a topography of auditory space. I. Normal hearing conditions.},
	journal = {Perception},
	volume = {13},
	year = {1984},
	number = {5},
	pages = {581-600},
	url = {http://www.biomedsearch.com/nih/Acuity-sound-localisation-topography-auditory/6535983.html},
	pubmedid = {6535983},
	issn = {0301-0066},
	abstract = {{{
		Eight subjects were required to localise a sound source (white noise through a speaker) which varied in position on both sides of the head over a range of elevations (-40 degrees to +40 degrees) and azimuths (0 degree to 180 degrees) at 10 degrees intervals. The perceived position of the source was indicated by pointing a special gun. Depression of the trigger activated a photographic system which recorded two views of the subject, the sound source, and the gun. The absolute and algebraic, azimuth and elevation errors were measured for all subjects at each position of the source. The variability of azimuth and elevation error was also computed. In a second experiment, four of the same subjects performed the same task but in this case visually located the sources. This experiment provided an estimate of inherent motor error in the pointing task. No differences in localisation acuity between sides were found, but there were significant differences between front and back regions. Azimuth and elevation error were well matched and low in the front. However, azimuth error increased in the regions behind the head, particularly for azimuth positions 120 degrees to 160 degrees. Larger increases were found for positions in the upper elevations of this region. Elevation error also increased in the upper elevations behind the head. A comparison of the auditory and visual data indicates that this pattern of error is not due to motor factors. The results are discussed in relation to the structural characteristics of the pinnae and modifications that they impose on incoming sound energy.
	}}},
	comments = {{{
		Referenced by military report: http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ada431963
		Pointing device: special gun that records aiming position on shot
		Estimuli white noise
		To discard pointing device errors compares them with visual localization
		Errors: Horizontal, vertical and absolute in degrees
		Conclusions
			Equal accuracy in left and right hemispheres
			More accuracy frontal, a and e
			Less athimuth accuracy behind 120-180 degrees maximmum
			Less elevation accuracy upper behind
		Table reproduced in page 41 of http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ada431963
	}}},
}

@article{OldfieldParker1984_acuityNoPinna,
	author = {Oldfield, S R and Parker, S P},
	title = {Acuity of sound localisation: a topography of auditory space. II. Pinna cues absent.},
	journal = {Perception},
	volume = {13},
	year = {1984},
	number = {5},
	pages = {601-17},
	url = {},
	pubmedid = {6535984},
	issn = {0301-0066},
	abstract = {{{
		 	The acuity of azimuth and elevation discrimination was measured under conditions in which the cues to localisation provided by the pinnae were removed. Four subjects localised a sound source (white noise through a speaker) which varied in position over a range of elevations (-40 degrees to +40 degrees) and azimuths (0 degree to 180 degrees), at 10 degrees intervals, on the left side of the head. Pinna cues were removed by the insertion of individually cast moulds in both pinnae. Each mould had an access hole to the auditory canal. The absolute and algebraic, azimuth and elevation errors were measured for all subjects at each position of the source. The variability of azimuth and elevation error was also computed. The performance of the subjects was compared to their performance under normal hearing conditions. Insertion of the pinnae moulds was found to increase substantially elevation error and the number of front/back reversals. The importance of the cues provided by the pinnae in these discriminations was thus confirmed. However, the increase in elevation error did not result in a corresponding increase in azimuth error. These findings provide support for the proposition that azimuth and elevation discrimination are coded independently.
	}}},
	comments = {{{
		Referenced by military tech report: http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ada431963
		Same test than OldfieldParker1984_acuityNormal but with molds in the pinna
		Increased front back reversals
		Increased elevation error
		No significative impact on azimuth error
	}}}
}

@article{OldfieldParker1986_acuityMonaural,
	author = {Oldfield, S R and Parker, S P},
	title = {Acuity of sound localisation: a topography of auditory space. III. Monaural hearing conditions.},
	journal = {Perception},
	volume = {15},
	year = {1986},
	number = {1},
	pages = {67-81},
	url = {http://www.biomedsearch.com/nih/Acuity-sound-localisation-topography-auditory/3774479.html},
	pubmedid = {3774479},
	issn = {0301-0066},
	abstract = {{{
		A study is reported in which the acuity of azimuth and elevation discrimination under monaural listening conditions was measured. Six subjects localised a sound source (white noise through a speaker) which varied in position over a range of elevations (-40 degrees to +40 degrees) and azimuths (0 degrees to 180 degrees), at 10 degrees intervals, on the left side of the head. Monaural listening conditions were established by the fitting of an ear defender and one earmuff to the right ear. The absolute and algebraic, azimuth and elevation errors were measured for all subjects at each position of the source. The results indicate that all subjects suffered a marked reduction of azimuth acuity under monaural conditions, although a coarse capacity to discriminate azimuth still remained. Considerable between-subject variability was observed. Front/back discrimination was retained, although it was slightly impaired compared to that observed under normal listening conditions. Elevation discrimination was, on the whole, quite good under monaural conditions. However, a comparison of the performance of these subjects under monaural conditions with that observed under normal listening conditions indicated that some reduction in elevation localisation acuity occurred in the frontal quadrants in the median plane and in the upper quadrants of more lateral source positions. The reduction in acuity seen in these regions is attributed to the loss of information from the pinna of the occluded ear rather than to the observed reduction in azimuth error. The results provide partial support for the binaural pinna disparity model.
	}}},
	comments = {{{
		Referenced by military report: http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ada431963
			Within the cone of confusion can not be resolved by binaural cues
			Pinna is dominant, shoulders effective when just low frequency
		Same test than OldfieldParker1984_acuityNormal but with a deafed ear
		Increased azimuth errors (still detected)
		Front back discrimination not as good but still
		Elevation not as bad as azimuth
		but not as good as normal conditions
			on frontal quadrants of median plane
			upper quadrants of upper positions
			attributed to loss of the other pinna deaff
	}}}
}
@book{Williams1999_FourierAcoustics,
	title = {{Fourier Acoustics}},
	author = {{Williams, Earl G.}},
	publisher = {{Academic Press}},
	year = 1999,
	url = {{http://books.google.es/books?id=vjfKLFBgMeIC}},
}

@conference{malham2001oformat,
	title={Spherical Harmonic Coding of Sound Objects - the Ambisonic 'O' Format},
	author={Malham, David},
	booktitle={Audio Engineering Society Conference: 19th International Conference: Surround Sound - Techniques, Technology, and Perception},
	month={6},
	year={2001},
	url={http://www.aes.org/e-lib/browse.cfm?elib=10070},
	download = {{{http://pcfarina.eng.unipr.it/Public/O-format/AES19-Malham.pdf}},
	comments = {{{
		Coding the shape of sources in ambisonics
	}}},
}



